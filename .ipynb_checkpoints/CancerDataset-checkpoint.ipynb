{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c89ec82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        self.weights = [np.random.randn(layers[i], layers[i+1]) for i in range(len(layers)-1)]\n",
    "        self.biases = [np.zeros((1, layers[i+1])) for i in range(len(layers)-1)]\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def forward_pass(self, X):\n",
    "        activations = [X]\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            z = np.dot(activations[-1], w) + b\n",
    "            activations.append(self.sigmoid(z))\n",
    "        return activations\n",
    "    \n",
    "    def backward_pass(self, X, Y, activations):\n",
    "        deltas = [(activations[-1] - Y) * self.sigmoid_derivative(activations[-1])]\n",
    "        for i in range(len(self.layers) - 2, 0, -1):\n",
    "            delta = np.dot(deltas[0], self.weights[i].T) * self.sigmoid_derivative(activations[i])\n",
    "            deltas.insert(0, delta)\n",
    "        return deltas\n",
    "    \n",
    "    \n",
    "    def compute_gradients(self, activations, deltas):\n",
    "        gradients_weights = [np.dot(activations[i].T, deltas[i]) for i in range(len(self.layers) - 1)]\n",
    "        gradients_biases = [np.sum(deltas[i], axis=0) for i in range(len(self.layers) - 1)]\n",
    "        return gradients_weights, gradients_biases\n",
    "    \n",
    "    def update_weights(self, gradients_weights, gradients_biases, learning_rate):\n",
    "        self.weights = [w - learning_rate * gw for w, gw in zip(self.weights, gradients_weights)]\n",
    "        self.biases = [b - learning_rate * gb for b, gb in zip(self.biases, gradients_biases)]\n",
    "    \n",
    "    def train(self, X, Y, learning_rate, lam, max_iterations, epsilon):\n",
    "        for iteration in range(max_iterations):\n",
    "            activations = self.forward_pass(X)\n",
    "            deltas = self.backward_pass(X, Y, activations)\n",
    "            gradients_weights, gradients_biases = self.compute_gradients(activations, deltas)\n",
    "            self.update_weights(gradients_weights, gradients_biases, learning_rate)\n",
    "            # Compute cost function\n",
    "            J = np.mean(np.square(activations[-1] - Y))\n",
    "            #print(f\"Iteration {iteration+1}, Cost: {J}\")\n",
    "            # Check for convergence\n",
    "            if J < epsilon:\n",
    "                print(f\"Converged at cost :{J} while Epsilon:{epsilon} \")\n",
    "                return J\n",
    "        return J\n",
    "            \n",
    "\n",
    "    def accuracy(self, y_true, y_pred):\n",
    "        correct = np.sum(np.all(y_true == y_pred, axis=1))\n",
    "        return correct / len(y_true)\n",
    "\n",
    "\n",
    "    def f1_score(self, y_true, y_pred):\n",
    "        tp = np.sum(np.logical_and(y_true, y_pred))\n",
    "        fp = np.sum(np.logical_and(np.logical_not(y_true), y_pred))\n",
    "        fn = np.sum(np.logical_and(y_true, np.logical_not(y_pred)))\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        return f1\n",
    "\n",
    "\n",
    "    def evaluate(self, X_test, y_test, J):\n",
    "        activations = self.forward_pass(X_test)[-1]\n",
    "        y_pred = (activations > 0.5).astype(int)\n",
    "        acc = self.accuracy(y_test, y_pred)\n",
    "        f1 = self.f1_score(y_test, y_pred)\n",
    "        return J, acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e79025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Load dataset\n",
    "df_cancer = pd.read_csv(\"/Users/noshitha/Downloads/hw4/datasets/hw3_cancer.csv\", delimiter=\"\\t\")\n",
    "\n",
    "# Extract features and target variable\n",
    "X_cancer = pd.get_dummies(df_cancer.drop(columns=['Class']))  # Features\n",
    "y_cancer = df_cancer['Class']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb932488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy Results:\n",
      "                            Architecture, Lambda  Mean Accuracy\n",
      "0                              ([9, 5, 2], 0.01)       0.964182\n",
      "1                               ([9, 5, 2], 0.1)       0.964203\n",
      "2                               ([9, 5, 2], 1.0)       0.965631\n",
      "3                           ([9, 6, 4, 2], 0.01)       0.964182\n",
      "4                            ([9, 6, 4, 2], 0.1)       0.964203\n",
      "5                            ([9, 6, 4, 2], 1.0)       0.967060\n",
      "6                        ([9, 7, 5, 3, 2], 0.01)       0.958489\n",
      "7                         ([9, 7, 5, 3, 2], 0.1)       0.965652\n",
      "8                         ([9, 7, 5, 3, 2], 1.0)       0.964182\n",
      "9                     ([9, 8, 6, 4, 3, 2], 0.01)       0.965611\n",
      "10                     ([9, 8, 6, 4, 3, 2], 0.1)       0.962754\n",
      "11                     ([9, 8, 6, 4, 3, 2], 1.0)       0.961325\n",
      "12  ([9, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 0.01)       0.655217\n",
      "13   ([9, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 0.1)       0.655217\n",
      "14   ([9, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 1.0)       0.655217\n",
      "15                            ([9, 20, 2], 0.01)       0.959917\n",
      "16                             ([9, 20, 2], 0.1)       0.957039\n",
      "17                             ([9, 20, 2], 1.0)       0.961346\n",
      "\n",
      "Mean F1 Score Results:\n",
      "                            Architecture, Lambda  Mean F1 Score\n",
      "0                              ([9, 5, 2], 0.01)       0.965683\n",
      "1                               ([9, 5, 2], 0.1)       0.965653\n",
      "2                               ([9, 5, 2], 1.0)       0.965631\n",
      "3                           ([9, 6, 4, 2], 0.01)       0.964182\n",
      "4                            ([9, 6, 4, 2], 0.1)       0.964953\n",
      "5                            ([9, 6, 4, 2], 1.0)       0.967060\n",
      "6                        ([9, 7, 5, 3, 2], 0.01)       0.958489\n",
      "7                         ([9, 7, 5, 3, 2], 0.1)       0.965652\n",
      "8                         ([9, 7, 5, 3, 2], 1.0)       0.964850\n",
      "9                     ([9, 8, 6, 4, 3, 2], 0.01)       0.965611\n",
      "10                     ([9, 8, 6, 4, 3, 2], 0.1)       0.962754\n",
      "11                     ([9, 8, 6, 4, 3, 2], 1.0)       0.961325\n",
      "12  ([9, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 0.01)       0.655217\n",
      "13   ([9, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 0.1)       0.655217\n",
      "14   ([9, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 1.0)       0.655217\n",
      "15                            ([9, 20, 2], 0.01)       0.965651\n",
      "16                             ([9, 20, 2], 0.1)       0.960656\n",
      "17                             ([9, 20, 2], 1.0)       0.966351\n",
      "\n",
      "Mean J cost Results:\n",
      "                            Architecture, Lambda  Mean J Cost\n",
      "0                              ([9, 5, 2], 0.01)     0.020982\n",
      "1                               ([9, 5, 2], 0.1)     0.020183\n",
      "2                               ([9, 5, 2], 1.0)     0.020552\n",
      "3                           ([9, 6, 4, 2], 0.01)     0.019713\n",
      "4                            ([9, 6, 4, 2], 0.1)     0.018123\n",
      "5                            ([9, 6, 4, 2], 1.0)     0.018785\n",
      "6                        ([9, 7, 5, 3, 2], 0.01)     0.018665\n",
      "7                         ([9, 7, 5, 3, 2], 0.1)     0.018562\n",
      "8                         ([9, 7, 5, 3, 2], 1.0)     0.017900\n",
      "9                     ([9, 8, 6, 4, 3, 2], 0.01)     0.019465\n",
      "10                     ([9, 8, 6, 4, 3, 2], 0.1)     0.016140\n",
      "11                     ([9, 8, 6, 4, 3, 2], 1.0)     0.017435\n",
      "12  ([9, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 0.01)     0.225906\n",
      "13   ([9, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 0.1)     0.225906\n",
      "14   ([9, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 1.0)     0.225906\n",
      "15                            ([9, 20, 2], 0.01)     0.016369\n",
      "16                             ([9, 20, 2], 0.1)     0.016976\n",
      "17                             ([9, 20, 2], 1.0)     0.017563\n"
     ]
    }
   ],
   "source": [
    "# Re-size data\n",
    "y_cancer_resized = y_cancer.values.reshape(-1, 1)\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the target variable\n",
    "y_encoded = encoder.fit_transform(y_cancer_resized)\n",
    "\n",
    "# Define model architectures and regularization parameters\n",
    "architectures = [\n",
    "    [X_cancer.shape[1], 5, y_encoded.shape[1]] , \n",
    "    [X_cancer.shape[1], 6, 4, y_encoded.shape[1]],  \n",
    "    [X_cancer.shape[1],7, 5, 3, y_encoded.shape[1]],  \n",
    "    [X_cancer.shape[1], 8, 6, 4, 3, y_encoded.shape[1]], \n",
    "    [X_cancer.shape[1],1,2,2,2,2,2,2,2,2,2, y_encoded.shape[1]], \n",
    "    [X_cancer.shape[1], 20, y_encoded.shape[1]]  \n",
    "]\n",
    "\n",
    "regularization_params = [0.01, 0.1, 1.0]  # Example regularization parameters\n",
    "\n",
    "# Initialize lists to store results\n",
    "results_accuracy = {}\n",
    "results_f1_score = {}\n",
    "results_J_cost = {}\n",
    "\n",
    "# Perform stratified k-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "for arch in architectures:\n",
    "    for lam in regularization_params:\n",
    "        accuracy_list = []\n",
    "        f1_score_list = []\n",
    "        J_list = []\n",
    "        for train_index, test_index in skf.split(X_cancer, y_cancer):\n",
    "            X_train, X_test = X_cancer.iloc[train_index], X_cancer.iloc[test_index]\n",
    "            y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
    "\n",
    "            mean = np.mean(X_train, axis=0)\n",
    "            std = np.std(X_train, axis=0)\n",
    "            X_train_normalized = (X_train - mean) / std\n",
    "            X_test_normalized = (X_test - mean) / std\n",
    "\n",
    "            model = NeuralNetwork(arch)\n",
    "            J = model.train(X_train_normalized, y_train, learning_rate=0.01, lam=lam, max_iterations=1000, epsilon=0.005)\n",
    "            J, accuracy, f1_score = model.evaluate(X_test_normalized, y_test, J)\n",
    "            accuracy_list.append(accuracy)\n",
    "            f1_score_list.append(f1_score)\n",
    "            J_list.append(J)\n",
    "\n",
    "        mean_accuracy = np.mean(accuracy_list)\n",
    "        mean_f1_score = np.mean(f1_score_list)\n",
    "        mean_J_cost = np.mean(J_list)\n",
    "\n",
    "        results_accuracy[(str(arch), lam)] = mean_accuracy\n",
    "        results_f1_score[(str(arch), lam)] = mean_f1_score\n",
    "        results_J_cost[(str(arch), lam)] = mean_J_cost\n",
    "\n",
    "# Convert the results into a DataFrame for tabular representation\n",
    "accuracy_df = pd.DataFrame(list(results_accuracy.items()), columns=['Architecture, Lambda', 'Mean Accuracy'])\n",
    "f1_score_df = pd.DataFrame(list(results_f1_score.items()), columns=['Architecture, Lambda', 'Mean F1 Score'])\n",
    "J_cost_df = pd.DataFrame(list(results_J_cost.items()), columns=['Architecture, Lambda', 'Mean J Cost'])\n",
    "\n",
    "print(\"Mean Accuracy Results:\")\n",
    "print(accuracy_df)\n",
    "print(\"\\nMean F1 Score Results:\")\n",
    "print(f1_score_df)\n",
    "print(\"\\nMean J cost Results:\")\n",
    "print(J_cost_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5719625a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14d3b8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Architecture, Lambda</th>\n",
       "      <th>Mean Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([9, 5, 2], 0.01)</td>\n",
       "      <td>0.964182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>([9, 5, 2], 0.1)</td>\n",
       "      <td>0.964203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>([9, 5, 2], 1.0)</td>\n",
       "      <td>0.965631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>([9, 6, 4, 2], 0.01)</td>\n",
       "      <td>0.964182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>([9, 6, 4, 2], 0.1)</td>\n",
       "      <td>0.964203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>([9, 6, 4, 2], 1.0)</td>\n",
       "      <td>0.967060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>([9, 7, 5, 3, 2], 0.01)</td>\n",
       "      <td>0.958489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>([9, 7, 5, 3, 2], 0.1)</td>\n",
       "      <td>0.965652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>([9, 7, 5, 3, 2], 1.0)</td>\n",
       "      <td>0.964182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>([9, 8, 6, 4, 3, 2], 0.01)</td>\n",
       "      <td>0.965611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>([9, 8, 6, 4, 3, 2], 0.1)</td>\n",
       "      <td>0.962754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>([9, 8, 6, 4, 3, 2], 1.0)</td>\n",
       "      <td>0.961325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>([9, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 0.01)</td>\n",
       "      <td>0.655217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>([9, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 0.1)</td>\n",
       "      <td>0.655217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>([9, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 1.0)</td>\n",
       "      <td>0.655217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>([9, 20, 2], 0.01)</td>\n",
       "      <td>0.959917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>([9, 20, 2], 0.1)</td>\n",
       "      <td>0.957039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>([9, 20, 2], 1.0)</td>\n",
       "      <td>0.961346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Architecture, Lambda  Mean Accuracy\n",
       "0                              ([9, 5, 2], 0.01)       0.964182\n",
       "1                               ([9, 5, 2], 0.1)       0.964203\n",
       "2                               ([9, 5, 2], 1.0)       0.965631\n",
       "3                           ([9, 6, 4, 2], 0.01)       0.964182\n",
       "4                            ([9, 6, 4, 2], 0.1)       0.964203\n",
       "5                            ([9, 6, 4, 2], 1.0)       0.967060\n",
       "6                        ([9, 7, 5, 3, 2], 0.01)       0.958489\n",
       "7                         ([9, 7, 5, 3, 2], 0.1)       0.965652\n",
       "8                         ([9, 7, 5, 3, 2], 1.0)       0.964182\n",
       "9                     ([9, 8, 6, 4, 3, 2], 0.01)       0.965611\n",
       "10                     ([9, 8, 6, 4, 3, 2], 0.1)       0.962754\n",
       "11                     ([9, 8, 6, 4, 3, 2], 1.0)       0.961325\n",
       "12  ([9, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 0.01)       0.655217\n",
       "13   ([9, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 0.1)       0.655217\n",
       "14   ([9, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 1.0)       0.655217\n",
       "15                            ([9, 20, 2], 0.01)       0.959917\n",
       "16                             ([9, 20, 2], 0.1)       0.957039\n",
       "17                             ([9, 20, 2], 1.0)       0.961346"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf90c0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Architecture, Lambda</th>\n",
       "      <th>Mean F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([9, 5, 2], 0.01)</td>\n",
       "      <td>0.965683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>([9, 5, 2], 0.1)</td>\n",
       "      <td>0.965653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>([9, 5, 2], 1.0)</td>\n",
       "      <td>0.965631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>([9, 6, 4, 2], 0.01)</td>\n",
       "      <td>0.964182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>([9, 6, 4, 2], 0.1)</td>\n",
       "      <td>0.964953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>([9, 6, 4, 2], 1.0)</td>\n",
       "      <td>0.967060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>([9, 7, 5, 3, 2], 0.01)</td>\n",
       "      <td>0.958489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>([9, 7, 5, 3, 2], 0.1)</td>\n",
       "      <td>0.965652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>([9, 7, 5, 3, 2], 1.0)</td>\n",
       "      <td>0.964850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>([9, 8, 6, 4, 3, 2], 0.01)</td>\n",
       "      <td>0.965611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>([9, 8, 6, 4, 3, 2], 0.1)</td>\n",
       "      <td>0.962754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>([9, 8, 6, 4, 3, 2], 1.0)</td>\n",
       "      <td>0.961325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>([9, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 0.01)</td>\n",
       "      <td>0.655217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>([9, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 0.1)</td>\n",
       "      <td>0.655217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>([9, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 1.0)</td>\n",
       "      <td>0.655217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>([9, 20, 2], 0.01)</td>\n",
       "      <td>0.965651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>([9, 20, 2], 0.1)</td>\n",
       "      <td>0.960656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>([9, 20, 2], 1.0)</td>\n",
       "      <td>0.966351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Architecture, Lambda  Mean F1 Score\n",
       "0                              ([9, 5, 2], 0.01)       0.965683\n",
       "1                               ([9, 5, 2], 0.1)       0.965653\n",
       "2                               ([9, 5, 2], 1.0)       0.965631\n",
       "3                           ([9, 6, 4, 2], 0.01)       0.964182\n",
       "4                            ([9, 6, 4, 2], 0.1)       0.964953\n",
       "5                            ([9, 6, 4, 2], 1.0)       0.967060\n",
       "6                        ([9, 7, 5, 3, 2], 0.01)       0.958489\n",
       "7                         ([9, 7, 5, 3, 2], 0.1)       0.965652\n",
       "8                         ([9, 7, 5, 3, 2], 1.0)       0.964850\n",
       "9                     ([9, 8, 6, 4, 3, 2], 0.01)       0.965611\n",
       "10                     ([9, 8, 6, 4, 3, 2], 0.1)       0.962754\n",
       "11                     ([9, 8, 6, 4, 3, 2], 1.0)       0.961325\n",
       "12  ([9, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 0.01)       0.655217\n",
       "13   ([9, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 0.1)       0.655217\n",
       "14   ([9, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 1.0)       0.655217\n",
       "15                            ([9, 20, 2], 0.01)       0.965651\n",
       "16                             ([9, 20, 2], 0.1)       0.960656\n",
       "17                             ([9, 20, 2], 1.0)       0.966351"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52bf6c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825417a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49048726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9318df15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d031edec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a735eeba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1408c281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6393484a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1487da54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08576023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Function to generate mini-batches\n",
    "def generate_mini_batches(X, y, batch_size):\n",
    "    num_samples = X.shape[0]\n",
    "    num_batches = num_samples // batch_size\n",
    "    mini_batches = []\n",
    "    shuffled_indices = np.random.permutation(num_samples)\n",
    "    X_shuffled = X[shuffled_indices]\n",
    "    y_shuffled = y[shuffled_indices]\n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        mini_batches.append((X_shuffled[start_idx:end_idx], y_shuffled[start_idx:end_idx]))\n",
    "    if num_samples % batch_size != 0:\n",
    "        mini_batches.append((X_shuffled[num_batches*batch_size:], y_shuffled[num_batches*batch_size:]))\n",
    "    return mini_batches\n",
    "\n",
    "\n",
    "def train_mini_batch(X_train, y_train, X_test, y_test, model, learning_rate, batch_size, max_iterations, epsilon):\n",
    "    training_errors = []\n",
    "    testing_errors = []\n",
    "    for iteration in range(max_iterations):\n",
    "        mini_batches = generate_mini_batches(X_train, y_train, batch_size)\n",
    "        for mini_batch in mini_batches:\n",
    "            X_mini_batch, y_mini_batch = mini_batch\n",
    "            J = model.train(X_mini_batch, y_mini_batch, learning_rate=learning_rate, lam=lam, max_iterations=1, epsilon=epsilon)\n",
    "        training_cost = np.mean(np.square(model.forward_pass(X_train)[-1] - y_train))  # Compute training cost\n",
    "        testing_cost = np.mean(np.square(model.forward_pass(X_test)[-1] - y_test))  # Compute testing cost\n",
    "        training_errors.append(training_cost)\n",
    "        testing_errors.append(testing_cost)\n",
    "        print(f\"Iteration {iteration+1}, Training Cost: {training_cost}, Testing Cost: {testing_cost}\")\n",
    "        # Check for convergence\n",
    "        if training_cost < epsilon:\n",
    "            print(f\"Converged at training cost :{training_cost} while Epsilon:{epsilon} \")\n",
    "            break\n",
    "    return training_errors, testing_errors\n",
    "\n",
    "# Plot learning curve\n",
    "def plot_learning_curve(training_errors, testing_errors, step_size):\n",
    "    iterations = range(1, len(training_errors) + 1)\n",
    "    plt.plot(iterations, training_errors, label='Training Error')\n",
    "    plt.plot(iterations, testing_errors, label='Testing Error')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.xlabel('Number of Training Examples')\n",
    "    plt.ylabel('Error (J)')\n",
    "    plt.xticks(np.arange(1, len(training_errors) + 1, step=step_size))\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bddf927b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([127, 164,  45, 311, 300, 279, 196, 108, 198,  92,\\n            ...\\n            195, 236, 314,  22, 223,  52, 270, 325,  37, 104],\\n           dtype='int64', length=348)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bm/l2zpyjxn2gqg_1d20xgx5z0w0000gn/T/ipykernel_15709/2769990677.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Train the model using mini-batch gradient descent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtraining_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_mini_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_normalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_normalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/bm/l2zpyjxn2gqg_1d20xgx5z0w0000gn/T/ipykernel_15709/3214990907.py\u001b[0m in \u001b[0;36mtrain_mini_batch\u001b[0;34m(X_train, y_train, X_test, y_test, model, learning_rate, batch_size, max_iterations, epsilon)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtesting_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mmini_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_mini_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmini_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmini_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mX_mini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_mini_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/bm/l2zpyjxn2gqg_1d20xgx5z0w0000gn/T/ipykernel_15709/3214990907.py\u001b[0m in \u001b[0;36mgenerate_mini_batches\u001b[0;34m(X, y, batch_size)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmini_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mshuffled_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mX_shuffled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshuffled_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0my_shuffled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshuffled_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3462\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3464\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3466\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1372\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([127, 164,  45, 311, 300, 279, 196, 108, 198,  92,\\n            ...\\n            195, 236, 314,  22, 223,  52, 270, 325,  37, 104],\\n           dtype='int64', length=348)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define your neural network model and parameters\n",
    "model = NeuralNetwork([X_house_votes.shape[1], 10, 8, y_encoded.shape[1]])  # Your desired architecture\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "max_iterations = 1000\n",
    "epsilon = 0.005\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_house_votes, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "X_train_normalized = (X_train - mean) / std\n",
    "X_test_normalized = (X_test - mean) / std\n",
    "\n",
    "# Train the model using mini-batch gradient descent\n",
    "training_errors, testing_errors = train_mini_batch(X_train_normalized, y_train, X_test_normalized, y_test, model, learning_rate, batch_size, max_iterations, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0025b465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learning curve\n",
    "step_size = 50  # Adjust as needed\n",
    "plot_learning_curve(training_errors, testing_errors, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4cc6e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
