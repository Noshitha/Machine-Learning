{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4487b3dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy Results for titanic DATASET:\n",
      "      Architecture, Lambda  Mean Accuracy\n",
      "0      ([21, 16, 2], 0.01)       0.796591\n",
      "1       ([21, 16, 2], 0.1)       0.806818\n",
      "2      ([21, 16, 2], 0.25)       0.798864\n",
      "3       ([21, 16, 2], 0.5)       0.806818\n",
      "4      ([21, 16, 2], 0.75)       0.792045\n",
      "5      ([21, 32, 2], 0.01)       0.811364\n",
      "6       ([21, 32, 2], 0.1)       0.796591\n",
      "7      ([21, 32, 2], 0.25)       0.803409\n",
      "8       ([21, 32, 2], 0.5)       0.804545\n",
      "9      ([21, 32, 2], 0.75)       0.798864\n",
      "10  ([21, 16, 8, 2], 0.01)       0.795455\n",
      "11   ([21, 16, 8, 2], 0.1)       0.794318\n",
      "12  ([21, 16, 8, 2], 0.25)       0.801136\n",
      "13   ([21, 16, 8, 2], 0.5)       0.801136\n",
      "14  ([21, 16, 8, 2], 0.75)       0.794318\n",
      "\n",
      "Mean F1 Score Results for titanic DATASET:\n",
      "      Architecture, Lambda  Mean F1 Score\n",
      "0      ([21, 16, 2], 0.01)       0.798600\n",
      "1       ([21, 16, 2], 0.1)       0.806818\n",
      "2      ([21, 16, 2], 0.25)       0.800239\n",
      "3       ([21, 16, 2], 0.5)       0.806818\n",
      "4      ([21, 16, 2], 0.75)       0.795533\n",
      "5      ([21, 32, 2], 0.01)       0.814505\n",
      "6       ([21, 32, 2], 0.1)       0.801102\n",
      "7      ([21, 32, 2], 0.25)       0.805426\n",
      "8       ([21, 32, 2], 0.5)       0.808356\n",
      "9      ([21, 32, 2], 0.75)       0.803518\n",
      "10  ([21, 16, 8, 2], 0.01)       0.795455\n",
      "11   ([21, 16, 8, 2], 0.1)       0.796141\n",
      "12  ([21, 16, 8, 2], 0.25)       0.801798\n",
      "13   ([21, 16, 8, 2], 0.5)       0.802272\n",
      "14  ([21, 16, 8, 2], 0.75)       0.794986\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        self.weights = [np.random.randn(layers[i], layers[i+1]) for i in range(len(layers)-1)]\n",
    "        self.biases = [np.zeros((1, layers[i+1])) for i in range(len(layers)-1)]\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def forward_pass(self, X):\n",
    "        activations = [X]\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            z = np.dot(activations[-1], w) + b\n",
    "            activations.append(self.sigmoid(z))\n",
    "        return activations\n",
    "    \n",
    "    def backward_pass(self, X, Y, activations):\n",
    "        deltas = [(activations[-1] - Y) * self.sigmoid_derivative(activations[-1])]\n",
    "        for i in range(len(self.layers) - 2, 0, -1):\n",
    "            delta = np.dot(deltas[0], self.weights[i].T) * self.sigmoid_derivative(activations[i])\n",
    "            deltas.insert(0, delta)\n",
    "        return deltas\n",
    "    \n",
    "    \n",
    "    def compute_gradients(self, activations, deltas):\n",
    "        gradients_weights = [np.dot(activations[i].T, deltas[i]) for i in range(len(self.layers) - 1)]\n",
    "        gradients_biases = [np.sum(deltas[i], axis=0) for i in range(len(self.layers) - 1)]\n",
    "        return gradients_weights, gradients_biases\n",
    "    \n",
    "    def update_weights(self, gradients_weights, gradients_biases, learning_rate):\n",
    "        self.weights = [w - learning_rate * gw for w, gw in zip(self.weights, gradients_weights)]\n",
    "        self.biases = [b - learning_rate * gb for b, gb in zip(self.biases, gradients_biases)]\n",
    "    \n",
    "    def train(self, X, Y, learning_rate, lam, max_iterations, epsilon):\n",
    "        for iteration in range(max_iterations):\n",
    "            activations = self.forward_pass(X)\n",
    "            deltas = self.backward_pass(X, Y, activations)\n",
    "            gradients_weights, gradients_biases = self.compute_gradients(activations, deltas)\n",
    "            self.update_weights(gradients_weights, gradients_biases, learning_rate)\n",
    "            # Compute cost function\n",
    "            J = np.mean(np.square(activations[-1] - Y))\n",
    "            #print(f\"Iteration {iteration+1}, Cost: {J}\")\n",
    "            # Check for convergence\n",
    "            if J < epsilon:\n",
    "                print(f\"Converged at cost :{J} while Epsilon:{epsilon} and Iteration: {iteration+1} \")\n",
    "                return J\n",
    "        return J\n",
    "            \n",
    "\n",
    "    def accuracy(self, y_true, y_pred):\n",
    "        correct = np.sum(np.all(y_true == y_pred, axis=1))\n",
    "        return correct / len(y_true)\n",
    "\n",
    "\n",
    "    def f1_score(self, y_true, y_pred):\n",
    "        tp = np.sum(np.logical_and(y_true, y_pred))\n",
    "        fp = np.sum(np.logical_and(np.logical_not(y_true), y_pred))\n",
    "        fn = np.sum(np.logical_and(y_true, np.logical_not(y_pred)))\n",
    "        precision = (tp) / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = (tp) / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        return f1\n",
    "\n",
    "\n",
    "    def evaluate(self, X_test, y_test, J):\n",
    "        activations = self.forward_pass(X_test)[-1]\n",
    "        y_pred = (activations > 0.5).astype(int)\n",
    "        acc = self.accuracy(y_test, y_pred)\n",
    "        f1 = self.f1_score(y_test, y_pred)\n",
    "        return J, acc, f1\n",
    "    \n",
    "    def k_fold_cross_validation(X, y, architectures, regularization_params, learning_rate, max_iterations, epsilon):\n",
    "        results_accuracy = {}\n",
    "        results_f1_score = {}\n",
    "        results_J_cost = {}\n",
    "        \n",
    "        num_splits = 10\n",
    "        fold_size = len(X) // num_splits\n",
    "\n",
    "        for arch in architectures:\n",
    "            for lam in regularization_params:\n",
    "                accuracy_list = []\n",
    "                f1_score_list = []\n",
    "                J_list = []\n",
    "                \n",
    "                for i in range(num_splits):\n",
    "                    start = i * fold_size\n",
    "                    end = (i + 1) * fold_size\n",
    "                    \n",
    "                    X_train = pd.concat([X[:start], X[end:]])\n",
    "                    y_train = np.concatenate([y[:start], y[end:]])\n",
    "                    X_test = X[start:end]\n",
    "                    y_test = y[start:end]\n",
    "\n",
    "\n",
    "                    model = NeuralNetwork(arch)\n",
    "                    J = model.train(X_train, y_train, learning_rate=learning_rate, lam=lam, max_iterations=max_iterations, epsilon=epsilon)\n",
    "                    J, accuracy, f1_score = model.evaluate(X_test, y_test, J)\n",
    "                    accuracy_list.append(accuracy)\n",
    "                    f1_score_list.append(f1_score)\n",
    "                    J_list.append(J)\n",
    "\n",
    "                mean_accuracy = np.mean(accuracy_list)\n",
    "                mean_f1_score = np.mean(f1_score_list)\n",
    "                mean_J_cost   = np.mean(J_list)\n",
    "\n",
    "                results_accuracy[(str(arch), lam)] = mean_accuracy\n",
    "                results_f1_score[(str(arch), lam)] = mean_f1_score\n",
    "                results_J_cost[(str(arch), lam)] = mean_J_cost\n",
    "\n",
    "        return results_accuracy, results_f1_score, results_J_cost\n",
    "\n",
    "\n",
    "df_titanic = pd.read_csv(\"/Users/noshitha/Downloads/final_project/titanic.csv\", delimiter=\",\")\n",
    "\n",
    "# Shuffle the dataset\n",
    "df_titanic_shuffle = shuffle(df_titanic)\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X_df = df_titanic_shuffle.drop(columns=['Survived'])\n",
    "\n",
    "# Convert categorical columns to categorical data type\n",
    "categorical_cols = ['Pclass', 'Siblings/Spouses Aboard', 'Parents/Children Aboard']\n",
    "for col in categorical_cols:\n",
    "    X_df[col] = X_df[col].astype('category')\n",
    "\n",
    "# Encoding on X:\n",
    "X_categorical = pd.get_dummies(X_df[['Pclass', 'Sex', 'Siblings/Spouses Aboard', 'Parents/Children Aboard']])\n",
    "X_categorical['Name'] = X_df['Name']  # Add Name column to X_categorical\n",
    "X_numerical = X_df[['Name', 'Age', 'Fare']]\n",
    "\n",
    "X_numerical_normal = X_numerical[['Age', 'Fare']]\n",
    "mean = np.mean(X_numerical_normal, axis=0)\n",
    "std = np.std(X_numerical_normal, axis=0)\n",
    "X_numerical_normalized = (X_numerical_normal - mean) / std\n",
    "\n",
    "# Combine normalized numerical columns with categorical columns\n",
    "X_combined = pd.concat([X_numerical[['Name']], X_numerical_normalized], axis=1)\n",
    "\n",
    "merged_df = pd.merge(X_categorical, X_combined, on='Name')\n",
    "X = merged_df.drop(columns=['Name'])\n",
    "y = df_titanic_shuffle['Survived']\n",
    "\n",
    "# Normalize data\n",
    "y_resized = y.values.reshape(-1, 1)\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the target variable\n",
    "y_encoded = encoder.fit_transform(y_resized)\n",
    "\n",
    "# Define model architectures and regularization parameters\n",
    "architectures = [ \n",
    "      [X.shape[1], 16, y_encoded.shape[1]],\n",
    "      [X.shape[1], 32, y_encoded.shape[1]],\n",
    "      [X.shape[1], 16, 8, y_encoded.shape[1]]\n",
    "#     [X.shape[1], 16, 8, y_encoded.shape[1]],\n",
    "#     [X.shape[1], 32, 16, 8, y_encoded.shape[1]],\n",
    "#     [X.shape[1], 64, 32, 16, 8, y_encoded.shape[1]]\n",
    "]\n",
    "\n",
    "regularization_params = [0.01, 0.10, 0.25, 0.50, 0.75] \n",
    "\n",
    "\n",
    "# Initialize lists to store results\n",
    "results_accuracy = {}\n",
    "results_f1_score = {}\n",
    "results_J_cost = {}\n",
    "\n",
    "# Perform stratified k-fold cross-validation\n",
    "results_accuracy, results_f1_score, results_J_cost = NeuralNetwork.k_fold_cross_validation(X, y_encoded, architectures, regularization_params, learning_rate=0.01 , max_iterations=3500, epsilon=0.005)\n",
    "\n",
    "# Convert the results into a DataFrame for tabular representation\n",
    "accuracy_df = pd.DataFrame(list(results_accuracy.items()), columns=['Architecture, Lambda', 'Mean Accuracy'])\n",
    "f1_score_df = pd.DataFrame(list(results_f1_score.items()), columns=['Architecture, Lambda', 'Mean F1 Score'])\n",
    "J_cost_df = pd.DataFrame(list(results_J_cost.items()), columns=['Architecture, Lambda', 'Mean J Cost'])\n",
    "\n",
    "print(\"Mean Accuracy Results for titanic DATASET:\")\n",
    "print(accuracy_df)\n",
    "print(\"\\nMean F1 Score Results for titanic DATASET:\")\n",
    "print(f1_score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "24d8a8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Architecture, Lambda</th>\n",
       "      <th>Mean J Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([21, 16, 2], 0.01)</td>\n",
       "      <td>0.092025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>([21, 16, 2], 0.1)</td>\n",
       "      <td>0.092037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>([21, 16, 2], 0.25)</td>\n",
       "      <td>0.091338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>([21, 16, 2], 0.5)</td>\n",
       "      <td>0.091675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>([21, 16, 2], 0.75)</td>\n",
       "      <td>0.092553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>([21, 32, 2], 0.01)</td>\n",
       "      <td>0.089125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>([21, 32, 2], 0.1)</td>\n",
       "      <td>0.090412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>([21, 32, 2], 0.25)</td>\n",
       "      <td>0.090392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>([21, 32, 2], 0.5)</td>\n",
       "      <td>0.090946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>([21, 32, 2], 0.75)</td>\n",
       "      <td>0.090463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>([21, 16, 8, 2], 0.01)</td>\n",
       "      <td>0.089891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>([21, 16, 8, 2], 0.1)</td>\n",
       "      <td>0.089344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>([21, 16, 8, 2], 0.25)</td>\n",
       "      <td>0.089760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>([21, 16, 8, 2], 0.5)</td>\n",
       "      <td>0.090360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>([21, 16, 8, 2], 0.75)</td>\n",
       "      <td>0.087820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Architecture, Lambda  Mean J Cost\n",
       "0      ([21, 16, 2], 0.01)     0.092025\n",
       "1       ([21, 16, 2], 0.1)     0.092037\n",
       "2      ([21, 16, 2], 0.25)     0.091338\n",
       "3       ([21, 16, 2], 0.5)     0.091675\n",
       "4      ([21, 16, 2], 0.75)     0.092553\n",
       "5      ([21, 32, 2], 0.01)     0.089125\n",
       "6       ([21, 32, 2], 0.1)     0.090412\n",
       "7      ([21, 32, 2], 0.25)     0.090392\n",
       "8       ([21, 32, 2], 0.5)     0.090946\n",
       "9      ([21, 32, 2], 0.75)     0.090463\n",
       "10  ([21, 16, 8, 2], 0.01)     0.089891\n",
       "11   ([21, 16, 8, 2], 0.1)     0.089344\n",
       "12  ([21, 16, 8, 2], 0.25)     0.089760\n",
       "13   ([21, 16, 8, 2], 0.5)     0.090360\n",
       "14  ([21, 16, 8, 2], 0.75)     0.087820"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_cost_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d7edf7ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Architecture, Lambda</th>\n",
       "      <th>Mean J Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([21, 16, 2], 0.01)</td>\n",
       "      <td>0.088060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>([21, 16, 2], 0.1)</td>\n",
       "      <td>0.087830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>([21, 16, 2], 0.25)</td>\n",
       "      <td>0.087460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>([21, 16, 2], 0.5)</td>\n",
       "      <td>0.086518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>([21, 16, 2], 0.75)</td>\n",
       "      <td>0.087575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Architecture, Lambda  Mean J Cost\n",
       "0  ([21, 16, 2], 0.01)     0.088060\n",
       "1   ([21, 16, 2], 0.1)     0.087830\n",
       "2  ([21, 16, 2], 0.25)     0.087460\n",
       "3   ([21, 16, 2], 0.5)     0.086518\n",
       "4  ([21, 16, 2], 0.75)     0.087575"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_cost_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "241a4a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Architecture, Lambda</th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Mean F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([21, 16, 2], 0.01)</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.813674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>([21, 16, 2], 0.1)</td>\n",
       "      <td>0.811364</td>\n",
       "      <td>0.813797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>([21, 16, 2], 0.25)</td>\n",
       "      <td>0.806818</td>\n",
       "      <td>0.807927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>([21, 16, 2], 0.5)</td>\n",
       "      <td>0.804545</td>\n",
       "      <td>0.804545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>([21, 16, 2], 0.75)</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.802740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Architecture, Lambda  Mean Accuracy  Mean F1 Score\n",
       "0  ([21, 16, 2], 0.01)       0.812500       0.813674\n",
       "1   ([21, 16, 2], 0.1)       0.811364       0.813797\n",
       "2  ([21, 16, 2], 0.25)       0.806818       0.807927\n",
       "3   ([21, 16, 2], 0.5)       0.804545       0.804545\n",
       "4  ([21, 16, 2], 0.75)       0.801136       0.802740"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge accuracy and f1_score DataFrames on 'Architecture, Lambda'\n",
    "merged_df = pd.merge(accuracy_df, f1_score_df, on='Architecture, Lambda')\n",
    "\n",
    "# Merge the merged DataFrame with J_cost_df on 'Architecture, Lambda'\n",
    "final_df = pd.merge(merged_df, J_cost_df, on='Architecture, Lambda')\n",
    "\n",
    "# Rename columns for clarity\n",
    "merged_df.columns = ['Architecture, Lambda', 'Mean Accuracy', 'Mean F1 Score']\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0791d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1cda2817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Architecture, Lambda</th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Mean F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([21, 16, 2], 0.01)</td>\n",
       "      <td>0.815909</td>\n",
       "      <td>0.816999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>([21, 16, 2], 0.1)</td>\n",
       "      <td>0.810227</td>\n",
       "      <td>0.814172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>([21, 16, 2], 0.25)</td>\n",
       "      <td>0.822727</td>\n",
       "      <td>0.826321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>([21, 16, 2], 0.5)</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.804181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>([21, 16, 2], 0.75)</td>\n",
       "      <td>0.802273</td>\n",
       "      <td>0.804069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>([21, 16, 8, 2], 0.01)</td>\n",
       "      <td>0.806818</td>\n",
       "      <td>0.808859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>([21, 16, 8, 2], 0.1)</td>\n",
       "      <td>0.810227</td>\n",
       "      <td>0.810708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>([21, 16, 8, 2], 0.25)</td>\n",
       "      <td>0.802273</td>\n",
       "      <td>0.802273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>([21, 16, 8, 2], 0.5)</td>\n",
       "      <td>0.809091</td>\n",
       "      <td>0.811195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>([21, 16, 8, 2], 0.75)</td>\n",
       "      <td>0.811364</td>\n",
       "      <td>0.813102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>([21, 32, 16, 8, 2], 0.01)</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.802682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>([21, 32, 16, 8, 2], 0.1)</td>\n",
       "      <td>0.797727</td>\n",
       "      <td>0.800575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>([21, 32, 16, 8, 2], 0.25)</td>\n",
       "      <td>0.797727</td>\n",
       "      <td>0.799843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>([21, 32, 16, 8, 2], 0.5)</td>\n",
       "      <td>0.805682</td>\n",
       "      <td>0.807933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>([21, 32, 16, 8, 2], 0.75)</td>\n",
       "      <td>0.811364</td>\n",
       "      <td>0.811364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>([21, 64, 32, 16, 8, 2], 0.01)</td>\n",
       "      <td>0.809091</td>\n",
       "      <td>0.809759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>([21, 64, 32, 16, 8, 2], 0.1)</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.801571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>([21, 64, 32, 16, 8, 2], 0.25)</td>\n",
       "      <td>0.804545</td>\n",
       "      <td>0.804545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>([21, 64, 32, 16, 8, 2], 0.5)</td>\n",
       "      <td>0.798864</td>\n",
       "      <td>0.800705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>([21, 64, 32, 16, 8, 2], 0.75)</td>\n",
       "      <td>0.806818</td>\n",
       "      <td>0.807479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Architecture, Lambda  Mean Accuracy  Mean F1 Score\n",
       "0              ([21, 16, 2], 0.01)       0.815909       0.816999\n",
       "1               ([21, 16, 2], 0.1)       0.810227       0.814172\n",
       "2              ([21, 16, 2], 0.25)       0.822727       0.826321\n",
       "3               ([21, 16, 2], 0.5)       0.801136       0.804181\n",
       "4              ([21, 16, 2], 0.75)       0.802273       0.804069\n",
       "5           ([21, 16, 8, 2], 0.01)       0.806818       0.808859\n",
       "6            ([21, 16, 8, 2], 0.1)       0.810227       0.810708\n",
       "7           ([21, 16, 8, 2], 0.25)       0.802273       0.802273\n",
       "8            ([21, 16, 8, 2], 0.5)       0.809091       0.811195\n",
       "9           ([21, 16, 8, 2], 0.75)       0.811364       0.813102\n",
       "10      ([21, 32, 16, 8, 2], 0.01)       0.800000       0.802682\n",
       "11       ([21, 32, 16, 8, 2], 0.1)       0.797727       0.800575\n",
       "12      ([21, 32, 16, 8, 2], 0.25)       0.797727       0.799843\n",
       "13       ([21, 32, 16, 8, 2], 0.5)       0.805682       0.807933\n",
       "14      ([21, 32, 16, 8, 2], 0.75)       0.811364       0.811364\n",
       "15  ([21, 64, 32, 16, 8, 2], 0.01)       0.809091       0.809759\n",
       "16   ([21, 64, 32, 16, 8, 2], 0.1)       0.800000       0.801571\n",
       "17  ([21, 64, 32, 16, 8, 2], 0.25)       0.804545       0.804545\n",
       "18   ([21, 64, 32, 16, 8, 2], 0.5)       0.798864       0.800705\n",
       "19  ([21, 64, 32, 16, 8, 2], 0.75)       0.806818       0.807479"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge accuracy and f1_score DataFrames on 'Architecture, Lambda'\n",
    "merged_df = pd.merge(accuracy_df, f1_score_df, on='Architecture, Lambda')\n",
    "\n",
    "# Merge the merged DataFrame with J_cost_df on 'Architecture, Lambda'\n",
    "final_df = pd.merge(merged_df, J_cost_df, on='Architecture, Lambda')\n",
    "\n",
    "# Rename columns for clarity\n",
    "merged_df.columns = ['Architecture, Lambda', 'Mean Accuracy', 'Mean F1 Score']\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e3f48f",
   "metadata": {},
   "source": [
    "## TO BE RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "edadf100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Function to generate mini-batches\n",
    "def generate_mini_batches(X, y, batch_size):\n",
    "    num_samples = X.shape[0]\n",
    "    num_batches = num_samples // batch_size\n",
    "    mini_batches = []\n",
    "    shuffled_indices = np.random.permutation(num_samples)\n",
    "    X_shuffled = X[shuffled_indices]\n",
    "    y_shuffled = y[shuffled_indices]\n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        mini_batches.append((X_shuffled[start_idx:end_idx], y_shuffled[start_idx:end_idx]))\n",
    "    if num_samples % batch_size != 0:\n",
    "        mini_batches.append((X_shuffled[num_batches*batch_size:], y_shuffled[num_batches*batch_size:]))\n",
    "    return mini_batches\n",
    "\n",
    "\n",
    "def train_mini_batch(X_train, y_train, model, learning_rate, batch_size, max_iterations, epsilon):\n",
    "    training_errors = []\n",
    "    for iteration in range(max_iterations):\n",
    "        mini_batches = generate_mini_batches(X_train, y_train, batch_size)\n",
    "        for mini_batch in mini_batches:\n",
    "            X_mini_batch, y_mini_batch = mini_batch\n",
    "            J = model.train(X_mini_batch, y_mini_batch, learning_rate=learning_rate, lam=0.25, max_iterations=2000, epsilon=epsilon)\n",
    "        training_cost = np.mean(np.square(model.forward_pass(X_train)[-1] - y_train))  # Compute training cost\n",
    "        training_errors.append(training_cost)\n",
    "        #print(f\"Iteration {iteration+1}, Training Cost: {training_cost}\")\n",
    "#         # Check for convergence\n",
    "#         if training_cost < epsilon:\n",
    "#             print(f\"Converged at training cost :{training_cost} while Epsilon:{epsilon} \")\n",
    "#             break\n",
    "    return training_errors\n",
    "\n",
    "# Plot learning curve\n",
    "def plot_learning_curve(training_errors, step_size):\n",
    "    iterations = range(1, len(training_errors) + 1)\n",
    "    plt.plot(iterations, training_errors, label='Training Error')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.xlabel('Number of Training Samples')\n",
    "    plt.ylabel('J values')\n",
    "    plt.xticks(np.arange(1, len(training_errors) + 1, step=step_size))\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812823a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_normalized:       Pclass_1  Pclass_2  Pclass_3  Sex_female  Sex_male  \\\n",
      "0    1.762521 -0.511601 -1.103404    1.350867 -1.350867   \n",
      "1   -0.567369 -0.511601  0.906287   -0.740266  0.740266   \n",
      "2   -0.567369 -0.511601  0.906287    1.350867 -1.350867   \n",
      "3   -0.567369  1.954649 -1.103404    1.350867 -1.350867   \n",
      "4   -0.567369 -0.511601  0.906287   -0.740266  0.740266   \n",
      "..        ...       ...       ...         ...       ...   \n",
      "882  1.762521 -0.511601 -1.103404    1.350867 -1.350867   \n",
      "883  1.762521 -0.511601 -1.103404   -0.740266  0.740266   \n",
      "884  1.762521 -0.511601 -1.103404    1.350867 -1.350867   \n",
      "885 -0.567369  1.954649 -1.103404    1.350867 -1.350867   \n",
      "886 -0.567369 -0.511601  0.906287    1.350867 -1.350867   \n",
      "\n",
      "     Siblings/Spouses Aboard_0  Siblings/Spouses Aboard_1  \\\n",
      "0                     0.684502                  -0.555211   \n",
      "1                     0.684502                  -0.555211   \n",
      "2                    -1.460916                   1.801116   \n",
      "3                     0.684502                  -0.555211   \n",
      "4                     0.684502                  -0.555211   \n",
      "..                         ...                        ...   \n",
      "882                   0.684502                  -0.555211   \n",
      "883                   0.684502                  -0.555211   \n",
      "884                   0.684502                  -0.555211   \n",
      "885                   0.684502                  -0.555211   \n",
      "886                   0.684502                  -0.555211   \n",
      "\n",
      "     Siblings/Spouses Aboard_2  Siblings/Spouses Aboard_3  \\\n",
      "0                    -0.180544                  -0.135535   \n",
      "1                    -0.180544                  -0.135535   \n",
      "2                    -0.180544                  -0.135535   \n",
      "3                    -0.180544                  -0.135535   \n",
      "4                    -0.180544                  -0.135535   \n",
      "..                         ...                        ...   \n",
      "882                  -0.180544                  -0.135535   \n",
      "883                  -0.180544                  -0.135535   \n",
      "884                  -0.180544                  -0.135535   \n",
      "885                  -0.180544                  -0.135535   \n",
      "886                  -0.180544                  -0.135535   \n",
      "\n",
      "     Siblings/Spouses Aboard_4  ...  Siblings/Spouses Aboard_8  \\\n",
      "0                    -0.143922  ...                  -0.089188   \n",
      "1                    -0.143922  ...                  -0.089188   \n",
      "2                    -0.143922  ...                  -0.089188   \n",
      "3                    -0.143922  ...                  -0.089188   \n",
      "4                    -0.143922  ...                  -0.089188   \n",
      "..                         ...  ...                        ...   \n",
      "882                  -0.143922  ...                  -0.089188   \n",
      "883                  -0.143922  ...                  -0.089188   \n",
      "884                  -0.143922  ...                  -0.089188   \n",
      "885                  -0.143922  ...                  -0.089188   \n",
      "886                  -0.143922  ...                  -0.089188   \n",
      "\n",
      "     Parents/Children Aboard_0  Parents/Children Aboard_1  \\\n",
      "0                    -1.778853                  -0.391722   \n",
      "1                     0.562160                  -0.391722   \n",
      "2                    -1.778853                   2.552832   \n",
      "3                    -1.778853                  -0.391722   \n",
      "4                     0.562160                  -0.391722   \n",
      "..                         ...                        ...   \n",
      "882                   0.562160                  -0.391722   \n",
      "883                   0.562160                  -0.391722   \n",
      "884                   0.562160                  -0.391722   \n",
      "885                   0.562160                  -0.391722   \n",
      "886                   0.562160                  -0.391722   \n",
      "\n",
      "     Parents/Children Aboard_2  Parents/Children Aboard_3  \\\n",
      "0                     3.176082                  -0.075292   \n",
      "1                    -0.314853                  -0.075292   \n",
      "2                    -0.314853                  -0.075292   \n",
      "3                     3.176082                  -0.075292   \n",
      "4                    -0.314853                  -0.075292   \n",
      "..                         ...                        ...   \n",
      "882                  -0.314853                  -0.075292   \n",
      "883                  -0.314853                  -0.075292   \n",
      "884                  -0.314853                  -0.075292   \n",
      "885                  -0.314853                  -0.075292   \n",
      "886                  -0.314853                  -0.075292   \n",
      "\n",
      "     Parents/Children Aboard_4  Parents/Children Aboard_5  \\\n",
      "0                    -0.067305                  -0.075292   \n",
      "1                    -0.067305                  -0.075292   \n",
      "2                    -0.067305                  -0.075292   \n",
      "3                    -0.067305                  -0.075292   \n",
      "4                    -0.067305                  -0.075292   \n",
      "..                         ...                        ...   \n",
      "882                  -0.067305                  -0.075292   \n",
      "883                  -0.067305                  -0.075292   \n",
      "884                  -0.067305                  -0.075292   \n",
      "885                  -0.067305                  -0.075292   \n",
      "886                  -0.067305                  -0.075292   \n",
      "\n",
      "     Parents/Children Aboard_6       Age      Fare  \n",
      "0                    -0.033596  0.462561  0.777718  \n",
      "1                    -0.033596 -0.458514 -0.490606  \n",
      "2                    -0.033596 -1.804700 -0.313652  \n",
      "3                    -0.033596 -1.521293 -0.121707  \n",
      "4                    -0.033596 -0.104255 -0.458364  \n",
      "..                         ...       ...       ...  \n",
      "882                  -0.033596 -0.387662  1.022087  \n",
      "883                  -0.033596 -0.529366  2.076777  \n",
      "884                  -0.033596  0.604265  0.958609  \n",
      "885                  -0.033596 -0.883626 -0.408117  \n",
      "886                  -0.033596 -0.104255 -0.493788  \n",
      "\n",
      "[887 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define your neural network model and parameters\n",
    "model = NeuralNetwork([X.shape[1], 16, y_encoded.shape[1]])  # Your desired architecture\n",
    "learning_rate = 0.01\n",
    "batch_size = 200\n",
    "max_iterations = 2000\n",
    "epsilon = 0.005\n",
    "\n",
    "\n",
    "# Standardize features\n",
    "mean = np.mean(X, axis=0)\n",
    "std = np.std(X, axis=0)\n",
    "X_normalized = (X - mean) / std\n",
    "\n",
    "print(\"X_normalized: \",X_normalized)\n",
    "\n",
    "# Train the model using mini-batch gradient descent\n",
    "training_errors = train_mini_batch(X_normalized.to_numpy(), y_encoded, model, learning_rate, batch_size, max_iterations, epsilon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5c990e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the learning curve\n",
    "step_size = 50\n",
    "plot_learning_curve(training_errors, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3f9262b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00015101434080728903,\n",
       " 0.00014564750486419187,\n",
       " 0.00016243411763689034,\n",
       " 0.00018351094106995662,\n",
       " 0.0001413664182069319,\n",
       " 0.00013322736356195818,\n",
       " 0.00017575799789746653,\n",
       " 0.00013948123255833349,\n",
       " 0.00018315874616125564,\n",
       " 0.00012870063768131496,\n",
       " 0.00013795432716112564,\n",
       " 0.0001393586294228058,\n",
       " 0.00012318399562895077,\n",
       " 0.00010988780620345019,\n",
       " 0.0001030493799800052,\n",
       " 0.00011024114150019828,\n",
       " 0.00010598941573792663,\n",
       " 0.00011083845621076925,\n",
       " 0.00012560908322939814,\n",
       " 0.00011637277392867296,\n",
       " 0.00012536196816982664,\n",
       " 0.0001250685602092324,\n",
       " 0.00013334932928829788,\n",
       " 0.00012595186020250172,\n",
       " 0.00011520652920928845,\n",
       " 0.00011331215812835182,\n",
       " 9.930537494513483e-05,\n",
       " 0.00010315016289039754,\n",
       " 0.00010781425867415212,\n",
       " 0.00010717361955583808,\n",
       " 0.00014144453398208447,\n",
       " 9.658112879920119e-05,\n",
       " 0.00010536519058408826,\n",
       " 0.0001189808708136688,\n",
       " 0.00016506114135395007,\n",
       " 9.39796674996747e-05,\n",
       " 0.0001189468667140917,\n",
       " 9.824743200639272e-05,\n",
       " 0.00011384312583797597,\n",
       " 0.00010650462579682854,\n",
       " 0.00012814830437201497,\n",
       " 0.00011377187072675557,\n",
       " 0.00011886309318239144,\n",
       " 9.927459410769304e-05,\n",
       " 0.00010025057772865925,\n",
       " 9.717446454762206e-05,\n",
       " 0.00011733793011084275,\n",
       " 9.706453675961388e-05,\n",
       " 0.00012615947553655743,\n",
       " 0.00010627574421794234,\n",
       " 0.00010349176129755904,\n",
       " 0.00010171990727672217,\n",
       " 0.00011030506994741291,\n",
       " 0.00010341698224088601,\n",
       " 0.00011404824574134682,\n",
       " 8.639371731793411e-05,\n",
       " 0.00010020521363756363,\n",
       " 8.020505650343195e-05,\n",
       " 0.0001153726956601839,\n",
       " 9.354042801535446e-05,\n",
       " 8.184118205433219e-05,\n",
       " 9.813034145993143e-05,\n",
       " 8.365674381568292e-05,\n",
       " 0.00010422932927672543,\n",
       " 8.618971451654609e-05,\n",
       " 9.006594496475808e-05,\n",
       " 9.860041446848995e-05,\n",
       " 9.564492876896558e-05,\n",
       " 8.555880418922275e-05,\n",
       " 0.00010258844763768752,\n",
       " 0.0001024701120411812,\n",
       " 9.75728074112296e-05,\n",
       " 9.643804195841134e-05,\n",
       " 0.00010435651189893808,\n",
       " 9.625873677975943e-05,\n",
       " 0.0001257385321443658,\n",
       " 9.89608393960932e-05,\n",
       " 9.20461281159403e-05,\n",
       " 0.00010172319717305177,\n",
       " 8.106193881294034e-05,\n",
       " 9.222759735476435e-05,\n",
       " 9.138472457292899e-05,\n",
       " 9.343631972629624e-05,\n",
       " 7.419391656083683e-05,\n",
       " 9.282137783192627e-05,\n",
       " 0.00011719611482356027,\n",
       " 9.79678159799675e-05,\n",
       " 8.558481191431848e-05,\n",
       " 8.826771256748074e-05,\n",
       " 7.353587857294628e-05,\n",
       " 8.368425267661708e-05,\n",
       " 9.05644004971861e-05,\n",
       " 7.298443839187448e-05,\n",
       " 8.106687513144107e-05,\n",
       " 9.201568251882373e-05,\n",
       " 0.00011120973640824225,\n",
       " 9.00500556148419e-05,\n",
       " 8.007813384772234e-05,\n",
       " 9.030398584916864e-05,\n",
       " 7.878220194382606e-05]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb9394d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
