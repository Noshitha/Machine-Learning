{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "beef5a70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_trees:  1\n",
      "Feature value not found in leaf nodes. Node: {'attribute': '13', 'leaf': {'<= 749.111801242236': {'attribute': '8', 'leaf': {'<= 0.3913567839195981': {'attribute': '1', 'leaf': {'<= 12.902106060605918': {'class_label': 2}, '> 12.902106060605918': {'class_label': 2}}}, '> 0.3913567839195981': {'attribute': '2', 'leaf': {'<= 3.176329704510097': {'class_label': 3}, '> 3.176329704510097': {'class_label': 3}}}}}, '> 749.111801242236': {'attribute': '8', 'leaf': {'<= 0.3379166666666667': {'attribute': '1', 'leaf': {'<= 13.517655310621155': {'class_label': 1}, '> 13.517655310621155': {'class_label': 1}}}, '> 0.3379166666666667': {'attribute': '2', 'leaf': {'<= 2.2331876606683827': {'class_label': 1}, '> 2.2331876606683827': {'class_label': 3}}}}}}}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'class_label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bm/l2zpyjxn2gqg_1d20xgx5z0w0000gn/T/ipykernel_34289/4061598685.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnum_trees\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mn_trees_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"num_trees: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_trees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0maccuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf_matrices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstratified_cross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_trees\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_subsample_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_subsample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracies:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precisions:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecisions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/bm/l2zpyjxn2gqg_1d20xgx5z0w0000gn/T/ipykernel_34289/4061598685.py\u001b[0m in \u001b[0;36mstratified_cross_validation\u001b[0;34m(X, y, n_folds, num_trees, max_depth, example_subsample_rate, attr_subsample_rate)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mtrees\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsampled_attributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_random_forest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_trees\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_subsample_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_subsample_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_random_forest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsampled_attributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_validation_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mall_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/bm/l2zpyjxn2gqg_1d20xgx5z0w0000gn/T/ipykernel_34289/4061598685.py\u001b[0m in \u001b[0;36mclassify_random_forest\u001b[0;34m(trees, subsampled_attributes, X_test)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_attributes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsampled_attributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mtest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msub_attributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mpredicted_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mtree_votes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Append predicted label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mclass_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_votes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtree_votes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Perform majority voting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/bm/l2zpyjxn2gqg_1d20xgx5z0w0000gn/T/ipykernel_34289/4061598685.py\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(tree, features)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Feature value not found in leaf nodes. Node:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"class_labels: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"node[class_labels]: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class_label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                 \u001b[0mclass_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"leaf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'class_label'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def entropy(labels):\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    probabilities = counts / len(labels)\n",
    "    entropy_value = -np.sum(probabilities * np.log2(probabilities))\n",
    "    return entropy_value\n",
    "\n",
    "def information_gain(y, x):\n",
    "    parent_entropy = entropy(y)\n",
    "    info_a = 0\n",
    "    for value in set(x):\n",
    "        partition_indices = x[x == value].index\n",
    "        partition_entropy = entropy(y[partition_indices])\n",
    "        info_a += len(partition_indices) / len(x) * partition_entropy\n",
    "    gain_a = parent_entropy - info_a\n",
    "    return gain_a\n",
    "\n",
    "def decision_tree(X_train, y_train, max_depth, current_depth=0):\n",
    "    if len(set(y_train)) == 1 or current_depth == max_depth or len(X_train.columns) == 0:\n",
    "        class_counts = Counter(y_train)\n",
    "        majority_class = class_counts.most_common(1)[0][0]\n",
    "        return {\"class_label\": majority_class}\n",
    "    \n",
    "    gains = {}\n",
    "    for attr in X_train.columns:\n",
    "        if X_train[attr].dtype == 'object':\n",
    "            gains[attr] = information_gain(y_train, X_train[attr])\n",
    "        else:\n",
    "            # For numerical attributes\n",
    "            attr_mean = X_train[attr].mean()\n",
    "            partition_indices_left = X_train[X_train[attr] <= attr_mean].index\n",
    "            partition_indices_right = X_train[X_train[attr] > attr_mean].index\n",
    "            partition_entropy_left = entropy(y_train[partition_indices_left])\n",
    "            partition_entropy_right = entropy(y_train[partition_indices_right])\n",
    "            weight_left = len(partition_indices_left) / len(X_train)\n",
    "            weight_right = len(partition_indices_right) / len(X_train)\n",
    "            info_a = weight_left * partition_entropy_left + weight_right * partition_entropy_right\n",
    "            gains[attr] = entropy(y_train) - info_a\n",
    "    \n",
    "    best_attr = max(gains, key=gains.get)\n",
    "    node = {\"attribute\": best_attr, \"leaf\": {}}\n",
    "    \n",
    "    if X_train[best_attr].dtype == 'object':\n",
    "        unique_values = X_train[best_attr].unique()\n",
    "        for value in unique_values:\n",
    "            partition_indices = X_train[X_train[best_attr] == value].index\n",
    "            node[\"leaf\"][value] = decision_tree(X_train.loc[partition_indices], y_train.loc[partition_indices], max_depth, current_depth + 1)\n",
    "    else:\n",
    "        attr_mean = X_train[best_attr].mean()\n",
    "        partition_indices_left = X_train[X_train[best_attr] <= attr_mean].index\n",
    "        partition_indices_right = X_train[X_train[best_attr] > attr_mean].index\n",
    "        node[\"leaf\"][\"<= \" + str(attr_mean)] = decision_tree(X_train.loc[partition_indices_left], y_train.loc[partition_indices_left], max_depth, current_depth + 1)\n",
    "        node[\"leaf\"][\"> \" + str(attr_mean)] = decision_tree(X_train.loc[partition_indices_right], y_train.loc[partition_indices_right], max_depth, current_depth + 1)\n",
    "    \n",
    "    return node\n",
    "\n",
    "def classify_random_forest(trees, subsampled_attributes, X_test):\n",
    "    class_labels = []\n",
    "    for _, test_row in X_test.iterrows():\n",
    "        tree_votes = []\n",
    "        for tree, sub_attributes in zip(trees, subsampled_attributes):\n",
    "            test_features = pd.DataFrame(test_row[sub_attributes]).T\n",
    "            predicted_label = classify(tree, test_features)\n",
    "            tree_votes.append(predicted_label[0])  # Append predicted label\n",
    "        class_labels.append(max(set(tree_votes), key=tree_votes.count))  # Perform majority voting\n",
    "    return class_labels\n",
    "\n",
    "def classify(tree, features):\n",
    "    class_labels = []\n",
    "    for _, feature in features.iterrows():\n",
    "        node = tree\n",
    "        while \"class_label\" not in node:\n",
    "            split_attr = node[\"attribute\"]\n",
    "            feature_value = feature[split_attr]\n",
    "            if feature_value in node[\"leaf\"]:\n",
    "                node = node[\"leaf\"][feature_value]\n",
    "            else:\n",
    "                print(\"Feature value not found in leaf nodes. Node:\", node)\n",
    "                temp = max(node[\"leaf\"].items(), key=lambda x: len(x[1]))[0]\n",
    "                print(\"class_labels: \",temp,\"node[class_labels]: \",node[\"class_label\"])\n",
    "                class_labels.append(max(node[\"leaf\"].items(), key=lambda x: len(x[1]))[0])\n",
    "                break\n",
    "        else:\n",
    "            if \"class_label\" in node:\n",
    "                class_labels.append(node[\"class_label\"])\n",
    "            else:\n",
    "                class_labels.append(max(node[\"leaf\"].items(), key=lambda x: len(x[1]))[0])\n",
    "    return class_labels\n",
    "\n",
    "\n",
    "# def classify(tree, features):\n",
    "#     class_labels = []\n",
    "#     for _, feature in features.iterrows():\n",
    "#         node = tree\n",
    "#         while \"class_label\" not in node:\n",
    "#             split_attr = node[\"attribute\"]\n",
    "#             feature_value = feature[split_attr]\n",
    "#             if feature_value in node[\"leaf\"]:\n",
    "#                 node = node[\"leaf\"][feature_value]\n",
    "#             else:\n",
    "#                 print(\"Feature value not found in leaf nodes. Node:\", node)\n",
    "#                 print(\"class_labels: \",class_labels,\"node[class_labels]: \",node[\"class_labels\"])\n",
    "#                 # If feature value not found in leaf node, return class label of the majority class in that node\n",
    "#                 class_labels.append(max(node[\"leaf\"].items(), key=lambda x: len(x[1]))[0])\n",
    "#                 break\n",
    "#         else:\n",
    "#             # Reached leaf node, append the class label\n",
    "#             class_labels.append(node[\"class_label\"])\n",
    "#     return class_labels\n",
    "\n",
    "\n",
    "\n",
    "def bootstrap_sampling(X, y):\n",
    "    indices = np.random.choice(len(X), size=len(X), replace=True)\n",
    "    return X.iloc[indices], y.iloc[indices]\n",
    "\n",
    "def fit_random_forest(num_trees, max_depth, example_subsample_rate, attr_subsample_rate, X_train, y_train):\n",
    "    trees = []\n",
    "    subsampled_attributes = []\n",
    "\n",
    "    for i in range(num_trees):\n",
    "        # Bootstrap sampling to create a bootstrapped dataset\n",
    "        bootstrapped_X, bootstrapped_y = bootstrap_sampling(X_train, y_train)\n",
    "\n",
    "        # Subsample attributes\n",
    "        subsampled_attr_indexes = np.random.choice(range(X_train.shape[1]), int(X_train.shape[1] * attr_subsample_rate), replace=False)\n",
    "        subsampled_attributes.append(subsampled_attr_indexes.tolist())\n",
    "        subsampled_X = bootstrapped_X.iloc[:, subsampled_attr_indexes]\n",
    "\n",
    "        # Build decision tree using the bootstrapped and subsampled dataset\n",
    "        tree = decision_tree(subsampled_X, bootstrapped_y, max_depth)\n",
    "        trees.append(tree)\n",
    "\n",
    "    return trees, subsampled_attributes\n",
    "\n",
    "def confusion_matrix(y_true, y_pred):\n",
    "    print(\"y_true: \",y_true,\"y_pred: \",y_pred)\n",
    "    classes = np.unique(np.concatenate([y_true, y_pred]))\n",
    "    n_classes = len(classes)\n",
    "    conf_matrix = np.zeros((n_classes, n_classes), dtype=int)\n",
    "\n",
    "    for i, true_label in enumerate(classes):\n",
    "        for j, pred_label in enumerate(classes):\n",
    "            conf_matrix[i, j] = np.sum((y_true == true_label) & (y_pred == pred_label))\n",
    "\n",
    "    return conf_matrix\n",
    "\n",
    "def calculate_metrics(conf_matrix):\n",
    "    TP = np.diag(conf_matrix)\n",
    "    FP = np.sum(conf_matrix, axis=0) - TP\n",
    "    FN = np.sum(conf_matrix, axis=1) - TP\n",
    "    TN = np.sum(conf_matrix) - (TP + FP + FN)\n",
    "\n",
    "    accuracy = np.sum(TP) / np.sum(conf_matrix)\n",
    "    \n",
    "    precision = np.where(TP + FP == 0, 0, TP / (TP + FP))\n",
    "    recall = np.where(TP + FN == 0, 0, TP / (TP + FN))\n",
    "    \n",
    "    # Handle division by zero or empty slices for F1-score\n",
    "    f1_score = np.zeros_like(precision)\n",
    "    non_zero_denominator = (precision + recall) != 0\n",
    "    f1_score[non_zero_denominator] = 2 * (precision[non_zero_denominator] * recall[non_zero_denominator]) / (precision[non_zero_denominator] + recall[non_zero_denominator])\n",
    "    \n",
    "    return accuracy, precision, recall, f1_score\n",
    "\n",
    "\n",
    "def stratified_cross_validation(X, y, n_folds, num_trees, max_depth, example_subsample_rate, attr_subsample_rate):\n",
    "    fold_size = len(X) // n_folds\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    conf_matrices = []\n",
    "    all_predictions = []\n",
    "\n",
    "    for i in range(n_folds):\n",
    "        start = i * fold_size\n",
    "        end = (i + 1) * fold_size\n",
    "\n",
    "        X_train_fold = pd.concat([X[:start], X[end:]])\n",
    "        y_train_fold = pd.concat([y[:start], y[end:]])\n",
    "\n",
    "        X_validation_fold = X[start:end]\n",
    "        y_validation_fold = y[start:end]\n",
    "        \n",
    "        trees, subsampled_attributes = fit_random_forest(num_trees, max_depth, example_subsample_rate, attr_subsample_rate, X_train_fold, y_train_fold)\n",
    "        predictions = classify_random_forest(trees, subsampled_attributes, X_validation_fold)\n",
    "        \n",
    "        all_predictions.extend(predictions)\n",
    "        \n",
    "        # Convert y_validation_fold to list\n",
    "        y_validation_fold_list = y_validation_fold.tolist()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        conf_matrix = confusion_matrix(y_validation_fold_list, predictions)\n",
    "        acc, prec, rec, f1 = calculate_metrics(conf_matrix)\n",
    "        \n",
    "        accuracies.append(acc)\n",
    "        precisions.append(prec)\n",
    "        recalls.append(rec)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        conf_matrices.append(conf_matrix)\n",
    "\n",
    "        mean_accuracy = np.mean(accuracies)\n",
    "        mean_precision = np.mean([np.mean(precision, axis=0) for precision in precisions], axis=0)\n",
    "        mean_recall = np.mean([np.mean(recall, axis=0) for recall in recalls], axis=0)\n",
    "        mean_f1_score = np.nanmean([np.nanmean(f1_score, axis=0) for f1_score in f1_scores], axis=0)\n",
    "\n",
    "    return mean_accuracy, mean_precision, mean_recall, mean_f1_score, conf_matrices\n",
    "        \n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df_wine = pd.read_csv(\"/Users/noshitha/Downloads/hw3/datasets/hw3_wine.csv\", delimiter=\"\\t\")\n",
    "\n",
    "    # Shuffle the dataset\n",
    "    df_wine_shuffle = shuffle(df_wine)\n",
    "\n",
    "    # Split the dataset into features and target variable\n",
    "    X = df_wine_shuffle.iloc[:, 1:]  # Assuming the first column is the target variable\n",
    "    y = df_wine_shuffle.iloc[:, 0] \n",
    "    \n",
    "    #n_trees_list = [1, 5, 10, 20, 30, 40, 50]\n",
    "    n_trees_list = [1]\n",
    "    n_folds = 10\n",
    "    max_depth = 3\n",
    "    example_subsample_rate = 0.5\n",
    "    attr_subsample_rate = 0.5\n",
    "    \n",
    "    accuracy  = []\n",
    "    precision = []\n",
    "    recall    = []\n",
    "    f1_score  = []\n",
    "    \n",
    "    for num_trees in n_trees_list:\n",
    "        print(\"num_trees: \",num_trees)\n",
    "        accuracies, precisions, recalls, f1_scores, conf_matrices = stratified_cross_validation(X, y, n_folds, num_trees, max_depth, example_subsample_rate, attr_subsample_rate)\n",
    "        print(\"Accuracies:\", accuracies)\n",
    "        print(\"Precisions:\", precisions)\n",
    "        print(\"Recalls:\", recalls)\n",
    "        print(\"F1-scores:\", f1_scores)\n",
    "        print(\"conf_matrices: \",conf_matrices)\n",
    "        accuracy.append(accuracies)\n",
    "        precision.append(precisions)\n",
    "        recall.append(recalls)\n",
    "        f1_score.append(f1_scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c6979e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># class</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   # class      1     2     3     4    5     6     7     8     9    10    11  \\\n",
       "0        1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29  5.64  1.04   \n",
       "1        1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28  4.38  1.05   \n",
       "2        1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81  5.68  1.03   \n",
       "3        1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18  7.80  0.86   \n",
       "4        1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82  4.32  1.04   \n",
       "\n",
       "     12    13  \n",
       "0  3.92  1065  \n",
       "1  3.40  1050  \n",
       "2  3.17  1185  \n",
       "3  3.45  1480  \n",
       "4  2.93   735  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10911236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>12.72</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.28</td>\n",
       "      <td>22.5</td>\n",
       "      <td>84</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.63</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.88</td>\n",
       "      <td>2.42</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>13.23</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.28</td>\n",
       "      <td>18.5</td>\n",
       "      <td>98</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.87</td>\n",
       "      <td>10.52</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.51</td>\n",
       "      <td>675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>12.34</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.46</td>\n",
       "      <td>21.0</td>\n",
       "      <td>98</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.31</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.38</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>13.76</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.70</td>\n",
       "      <td>19.5</td>\n",
       "      <td>132</td>\n",
       "      <td>2.95</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.35</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>12.42</td>\n",
       "      <td>4.43</td>\n",
       "      <td>2.73</td>\n",
       "      <td>26.5</td>\n",
       "      <td>102</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3.12</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         1     2     3     4    5     6     7     8     9     10    11    12  \\\n",
       "107  12.72  1.75  2.28  22.5   84  1.38  1.76  0.48  1.63   3.30  0.88  2.42   \n",
       "153  13.23  3.30  2.28  18.5   98  1.80  0.83  0.61  1.87  10.52  0.56  1.51   \n",
       "102  12.34  2.45  2.46  21.0   98  2.56  2.11  0.34  1.31   2.80  0.80  3.38   \n",
       "33   13.76  1.53  2.70  19.5  132  2.95  2.74  0.50  1.35   5.40  1.25  3.00   \n",
       "122  12.42  4.43  2.73  26.5  102  2.20  2.13  0.43  1.71   2.08  0.92  3.12   \n",
       "\n",
       "       13  \n",
       "107   488  \n",
       "153   675  \n",
       "102   438  \n",
       "33   1235  \n",
       "122   365  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "026105fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107    2\n",
       "153    3\n",
       "102    2\n",
       "33     1\n",
       "122    2\n",
       "Name: # class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2eb6ae36",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conf_matrices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bm/l2zpyjxn2gqg_1d20xgx5z0w0000gn/T/ipykernel_34289/602420917.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_matrices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'conf_matrices' is not defined"
     ]
    }
   ],
   "source": [
    "print(conf_matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2de6a20",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d5c2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n_trees_list, accuracy, marker='o')\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Number of Trees - House Votes Dataset')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4209f209",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217bf335",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n_trees_list, precision, marker='o')\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.ylabel('Precision'))\n",
    "plt.title('Precision vs Number of Trees - House Votes Dataset')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d38d0b",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d449f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n_trees_list, precision, marker='o')\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.ylabel('Recall'))\n",
    "plt.title('Recall vs Number of Trees - House Votes Dataset')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af62639",
   "metadata": {},
   "source": [
    "### F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea0c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n_trees_list, precision, marker='o')\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.ylabel('F1_score'))\n",
    "plt.title('F1_score vs Number of Trees - House Votes Dataset')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caf8656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8f0be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b965ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d3913d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fe845c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfb8718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
