{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9094670c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy Results:\n",
      "                      Architecture, Lambda  Mean Accuracy\n",
      "0           ([9, 12, 10, 8, 6, 4, 3], 0.1)       0.197959\n",
      "1           ([9, 12, 10, 8, 6, 4, 3], 1.0)       0.228571\n",
      "2   ([9, 20, 15, 12, 10, 8, 6, 4, 3], 0.1)       0.110204\n",
      "3   ([9, 20, 15, 12, 10, 8, 6, 4, 3], 1.0)       0.216327\n",
      "4            ([9, 30, 30, 30, 30, 3], 0.1)       0.334014\n",
      "5            ([9, 30, 30, 30, 30, 3], 1.0)       0.297279\n",
      "6       ([9, 3, 6, 2, 5, 2, 6, 3, 3], 0.1)       0.000000\n",
      "7       ([9, 3, 6, 2, 5, 2, 6, 3, 3], 1.0)       0.000000\n",
      "8        ([9, 20, 15, 10, 15, 20, 3], 0.1)       0.315646\n",
      "9        ([9, 20, 15, 10, 15, 20, 3], 1.0)       0.304082\n",
      "10       ([9, 50, 40, 30, 20, 10, 3], 0.1)       0.355102\n",
      "11       ([9, 50, 40, 30, 20, 10, 3], 1.0)       0.368027\n",
      "12          ([9, 4, 10, 4, 10, 4, 3], 0.1)       0.154422\n",
      "13          ([9, 4, 10, 4, 10, 4, 3], 1.0)       0.167347\n",
      "\n",
      "Mean F1 Score Results:\n",
      "                      Architecture, Lambda  Mean F1 Score\n",
      "0           ([9, 12, 10, 8, 6, 4, 3], 0.1)       0.250287\n",
      "1           ([9, 12, 10, 8, 6, 4, 3], 1.0)       0.292447\n",
      "2   ([9, 20, 15, 12, 10, 8, 6, 4, 3], 0.1)       0.144243\n",
      "3   ([9, 20, 15, 12, 10, 8, 6, 4, 3], 1.0)       0.275194\n",
      "4            ([9, 30, 30, 30, 30, 3], 0.1)       0.384765\n",
      "5            ([9, 30, 30, 30, 30, 3], 1.0)       0.343258\n",
      "6       ([9, 3, 6, 2, 5, 2, 6, 3, 3], 0.1)       0.000000\n",
      "7       ([9, 3, 6, 2, 5, 2, 6, 3, 3], 1.0)       0.000000\n",
      "8        ([9, 20, 15, 10, 15, 20, 3], 0.1)       0.371971\n",
      "9        ([9, 20, 15, 10, 15, 20, 3], 1.0)       0.352693\n",
      "10       ([9, 50, 40, 30, 20, 10, 3], 0.1)       0.395399\n",
      "11       ([9, 50, 40, 30, 20, 10, 3], 1.0)       0.412129\n",
      "12          ([9, 4, 10, 4, 10, 4, 3], 0.1)       0.194207\n",
      "13          ([9, 4, 10, 4, 10, 4, 3], 1.0)       0.211833\n",
      "\n",
      "Mean J cost Results:\n",
      "                      Architecture, Lambda  Mean J Cost\n",
      "0           ([9, 12, 10, 8, 6, 4, 3], 0.1)     0.175204\n",
      "1           ([9, 12, 10, 8, 6, 4, 3], 1.0)     0.171210\n",
      "2   ([9, 20, 15, 12, 10, 8, 6, 4, 3], 0.1)     0.187342\n",
      "3   ([9, 20, 15, 12, 10, 8, 6, 4, 3], 1.0)     0.177286\n",
      "4            ([9, 30, 30, 30, 30, 3], 0.1)     0.144231\n",
      "5            ([9, 30, 30, 30, 30, 3], 1.0)     0.144554\n",
      "6       ([9, 3, 6, 2, 5, 2, 6, 3, 3], 0.1)     0.213360\n",
      "7       ([9, 3, 6, 2, 5, 2, 6, 3, 3], 1.0)     0.213356\n",
      "8        ([9, 20, 15, 10, 15, 20, 3], 0.1)     0.157180\n",
      "9        ([9, 20, 15, 10, 15, 20, 3], 1.0)     0.156591\n",
      "10       ([9, 50, 40, 30, 20, 10, 3], 0.1)     0.134394\n",
      "11       ([9, 50, 40, 30, 20, 10, 3], 1.0)     0.136001\n",
      "12          ([9, 4, 10, 4, 10, 4, 3], 0.1)     0.190104\n",
      "13          ([9, 4, 10, 4, 10, 4, 3], 1.0)     0.186867\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        self.weights = [np.random.randn(layers[i], layers[i+1]) for i in range(len(layers)-1)]\n",
    "        self.biases = [np.zeros((1, layers[i+1])) for i in range(len(layers)-1)]\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def forward_pass(self, X):\n",
    "        activations = [X]\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            z = np.dot(activations[-1], w) + b\n",
    "            activations.append(self.sigmoid(z))\n",
    "        return activations\n",
    "    \n",
    "    def backward_pass(self, X, Y, activations):\n",
    "        deltas = [(activations[-1] - Y) * self.sigmoid_derivative(activations[-1])]\n",
    "        for i in range(len(self.layers) - 2, 0, -1):\n",
    "            delta = np.dot(deltas[0], self.weights[i].T) * self.sigmoid_derivative(activations[i])\n",
    "            deltas.insert(0, delta)\n",
    "        return deltas\n",
    "    \n",
    "    \n",
    "    def compute_gradients(self, activations, deltas):\n",
    "        gradients_weights = [np.dot(activations[i].T, deltas[i]) for i in range(len(self.layers) - 1)]\n",
    "        gradients_biases = [np.sum(deltas[i], axis=0) for i in range(len(self.layers) - 1)]\n",
    "        return gradients_weights, gradients_biases\n",
    "    \n",
    "    def update_weights(self, gradients_weights, gradients_biases, learning_rate):\n",
    "        self.weights = [w - learning_rate * gw for w, gw in zip(self.weights, gradients_weights)]\n",
    "        self.biases = [b - learning_rate * gb for b, gb in zip(self.biases, gradients_biases)]\n",
    "    \n",
    "    def train(self, X, Y, learning_rate, lam, max_iterations, epsilon):\n",
    "        for iteration in range(max_iterations):\n",
    "            activations = self.forward_pass(X)\n",
    "            deltas = self.backward_pass(X, Y, activations)\n",
    "            gradients_weights, gradients_biases = self.compute_gradients(activations, deltas)\n",
    "            self.update_weights(gradients_weights, gradients_biases, learning_rate)\n",
    "            # Compute cost function\n",
    "            J = np.mean(np.square(activations[-1] - Y))\n",
    "            #print(f\"Iteration {iteration+1}, Cost: {J}\")\n",
    "            # Check for convergence\n",
    "            if J < epsilon:\n",
    "                #print(f\"Converged at cost :{J} while Epsilon:{epsilon} \")\n",
    "                return J\n",
    "        return J\n",
    "            \n",
    "\n",
    "    def accuracy(self, y_true, y_pred):\n",
    "        correct = np.sum(np.all(y_true == y_pred, axis=1))\n",
    "        return correct / len(y_true)\n",
    "\n",
    "\n",
    "    def f1_score(self, y_true, y_pred):\n",
    "        tp = np.sum(np.logical_and(y_true, y_pred))\n",
    "        fp = np.sum(np.logical_and(np.logical_not(y_true), y_pred))\n",
    "        fn = np.sum(np.logical_and(y_true, np.logical_not(y_pred)))\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        return f1\n",
    "\n",
    "\n",
    "    def evaluate(self, X_test, y_test, J):\n",
    "        activations = self.forward_pass(X_test)[-1]\n",
    "        y_pred = (activations > 0.5).astype(int)\n",
    "        acc = self.accuracy(y_test, y_pred)\n",
    "        f1 = self.f1_score(y_test, y_pred)\n",
    "        return J, acc, f1\n",
    "    \n",
    "    def k_fold_cross_validation(X, y, architectures, regularization_params, learning_rate, max_iterations, epsilon):\n",
    "        results_accuracy = {}\n",
    "        results_f1_score = {}\n",
    "        results_J_cost = {}\n",
    "        \n",
    "        num_splits = 10\n",
    "        fold_size = len(X) // num_splits\n",
    "\n",
    "        for arch in architectures:\n",
    "            for lam in regularization_params:\n",
    "                accuracy_list = []\n",
    "                f1_score_list = []\n",
    "                J_list = []\n",
    "                \n",
    "                for i in range(num_splits):\n",
    "                    start = i * fold_size\n",
    "                    end = (i + 1) * fold_size\n",
    "                    \n",
    "                    X_train = pd.concat([X[:start], X[end:]])\n",
    "                    y_train = np.concatenate([y[:start], y[end:]])\n",
    "                    X_test = X[start:end]\n",
    "                    y_test = y[start:end]\n",
    "\n",
    "                    mean = np.mean(X_train, axis=0)\n",
    "                    std = np.std(X_train, axis=0)\n",
    "                    X_train_normalized = (X_train - mean) / std\n",
    "                    X_test_normalized = (X_test - mean) / std\n",
    "\n",
    "                    model = NeuralNetwork(arch)\n",
    "                    J = model.train(X_train_normalized, y_train, learning_rate=learning_rate, lam=lam, max_iterations=max_iterations, epsilon=epsilon)\n",
    "                    J, accuracy, f1_score = model.evaluate(X_test_normalized, y_test, J)\n",
    "                    accuracy_list.append(accuracy)\n",
    "                    f1_score_list.append(f1_score)\n",
    "                    J_list.append(J)\n",
    "\n",
    "                mean_accuracy = np.mean(accuracy_list)\n",
    "                mean_f1_score = np.mean(f1_score_list)\n",
    "                mean_J_cost   = np.mean(J_list)\n",
    "\n",
    "                results_accuracy[(str(arch), lam)] = mean_accuracy\n",
    "                results_f1_score[(str(arch), lam)] = mean_f1_score\n",
    "                results_J_cost[(str(arch), lam)] = mean_J_cost\n",
    "\n",
    "        return results_accuracy, results_f1_score, results_J_cost\n",
    "\n",
    "#Load dataset\n",
    "data_file = \"/Users/noshitha/Downloads/contraceptive+method+choice/cmc.data\"\n",
    "column_names = [\n",
    "    \"Wife_age\", \"Wife_education\", \"Husband_education\", \"Number_of_children_ever_born\",\n",
    "    \"Wife_religion\", \"Wife_working\", \"Husband_occupation\", \"Standard-of-living_index\",\n",
    "    \"Media_exposure\", \"Contraceptive_method_used\"\n",
    "]\n",
    "cmc_df = pd.read_csv(data_file, names=column_names) \n",
    "\n",
    "# Extract features and target variable\n",
    "X_cmc = pd.get_dummies(cmc_df.drop(columns=['Contraceptive_method_used']))  # Features\n",
    "y_cmc = cmc_df['Contraceptive_method_used']  \n",
    "\n",
    "# Re-size data\n",
    "y_cmc_resized = y_cmc.values.reshape(-1, 1)\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the target variable\n",
    "y_encoded = encoder.fit_transform(y_cmc_resized)\n",
    "\n",
    "# Define model architectures and regularization parameters\n",
    "architectures = [\n",
    "    [X_cmc.shape[1], 12, 10, 8, 6, 4, y_encoded.shape[1]], \n",
    "    [X_cmc.shape[1], 20, 15, 12, 10, 8, 6, 4, y_encoded.shape[1]], \n",
    "    [X_cmc.shape[1], 30,30,30,30, y_encoded.shape[1]], \n",
    "    [X_cmc.shape[1], 3, 6, 2, 5, 2, 6, 3, y_encoded.shape[1]], \n",
    "    [X_cmc.shape[1], 20, 15, 10, 15, 20, y_encoded.shape[1]], \n",
    "    [X_cmc.shape[1], 50, 40, 30, 20, 10, y_encoded.shape[1]], \n",
    "    [X_cmc.shape[1], 4, 10, 4, 10, 4, y_encoded.shape[1]]      \n",
    "]\n",
    "\n",
    "regularization_params = [0.1, 1.0]\n",
    "\n",
    "# Initialize lists to store results\n",
    "results_accuracy = {}\n",
    "results_f1_score = {}\n",
    "results_J_cost = {}\n",
    "\n",
    "# Perform stratified k-fold cross-validation\n",
    "results_accuracy, results_f1_score, results_J_cost = NeuralNetwork.k_fold_cross_validation(X_cmc, y_encoded, architectures, regularization_params, learning_rate=0.001, max_iterations=2500, epsilon=0.0001)\n",
    "\n",
    "# Convert the results into a DataFrame for tabular representation\n",
    "accuracy_df = pd.DataFrame(list(results_accuracy.items()), columns=['Architecture, Lambda', 'Mean Accuracy'])\n",
    "f1_score_df = pd.DataFrame(list(results_f1_score.items()), columns=['Architecture, Lambda', 'Mean F1 Score'])\n",
    "J_cost_df = pd.DataFrame(list(results_J_cost.items()), columns=['Architecture, Lambda', 'Mean J Cost'])\n",
    "\n",
    "print(\"Mean Accuracy Results:\")\n",
    "print(accuracy_df)\n",
    "print(\"\\nMean F1 Score Results:\")\n",
    "print(f1_score_df)\n",
    "print(\"\\nMean J cost Results:\")\n",
    "print(J_cost_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876f9cae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
