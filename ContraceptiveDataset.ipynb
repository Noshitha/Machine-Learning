{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bad2e326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy Results:\n",
      "                             Architecture, Lambda  Mean Accuracy\n",
      "0                         ([9, 30, 25, 3], 1e-06)       0.219048\n",
      "1                         ([9, 30, 25, 3], 1e-05)       0.191837\n",
      "2                         ([9, 30, 25, 3], 0.001)       0.217007\n",
      "3                  ([9, 20, 15, 10, 5, 3], 1e-06)       0.006803\n",
      "4                  ([9, 20, 15, 10, 5, 3], 1e-05)       0.027891\n",
      "5                  ([9, 20, 15, 10, 5, 3], 0.001)       0.025170\n",
      "6                 ([9, 25, 20, 15, 10, 3], 1e-06)       0.114966\n",
      "7                 ([9, 25, 20, 15, 10, 3], 1e-05)       0.155782\n",
      "8                 ([9, 25, 20, 15, 10, 3], 0.001)       0.144218\n",
      "9                     ([9, 60, 80, 70, 3], 1e-06)       0.240816\n",
      "10                    ([9, 60, 80, 70, 3], 1e-05)       0.264626\n",
      "11                    ([9, 60, 80, 70, 3], 0.001)       0.278912\n",
      "12                ([9, 80, 60, 40, 30, 3], 1e-06)       0.255102\n",
      "13                ([9, 80, 60, 40, 30, 3], 1e-05)       0.242177\n",
      "14                ([9, 80, 60, 40, 30, 3], 0.001)       0.257143\n",
      "15                ([9, 70, 80, 60, 70, 3], 1e-06)       0.282993\n",
      "16                ([9, 70, 80, 60, 70, 3], 1e-05)       0.287755\n",
      "17                ([9, 70, 80, 60, 70, 3], 0.001)       0.284354\n",
      "18          ([9, 120, 100, 80, 60, 40, 3], 1e-06)       0.280952\n",
      "19          ([9, 120, 100, 80, 60, 40, 3], 1e-05)       0.305442\n",
      "20          ([9, 120, 100, 80, 60, 40, 3], 0.001)       0.317007\n",
      "21  ([9, 150, 120, 100, 110, 130, 140, 3], 1e-06)       0.218367\n",
      "22  ([9, 150, 120, 100, 110, 130, 140, 3], 1e-05)       0.334014\n",
      "23  ([9, 150, 120, 100, 110, 130, 140, 3], 0.001)       0.336735\n",
      "\n",
      "Mean F1 Score Results:\n",
      "                             Architecture, Lambda  Mean F1 Score\n",
      "0                         ([9, 30, 25, 3], 1e-06)       0.289704\n",
      "1                         ([9, 30, 25, 3], 1e-05)       0.256600\n",
      "2                         ([9, 30, 25, 3], 0.001)       0.289096\n",
      "3                  ([9, 20, 15, 10, 5, 3], 1e-06)       0.010811\n",
      "4                  ([9, 20, 15, 10, 5, 3], 1e-05)       0.041994\n",
      "5                  ([9, 20, 15, 10, 5, 3], 0.001)       0.041075\n",
      "6                 ([9, 25, 20, 15, 10, 3], 1e-06)       0.171289\n",
      "7                 ([9, 25, 20, 15, 10, 3], 1e-05)       0.220542\n",
      "8                 ([9, 25, 20, 15, 10, 3], 0.001)       0.208499\n",
      "9                     ([9, 60, 80, 70, 3], 1e-06)       0.311444\n",
      "10                    ([9, 60, 80, 70, 3], 1e-05)       0.340499\n",
      "11                    ([9, 60, 80, 70, 3], 0.001)       0.353113\n",
      "12                ([9, 80, 60, 40, 30, 3], 1e-06)       0.330666\n",
      "13                ([9, 80, 60, 40, 30, 3], 1e-05)       0.304899\n",
      "14                ([9, 80, 60, 40, 30, 3], 0.001)       0.324657\n",
      "15                ([9, 70, 80, 60, 70, 3], 1e-06)       0.388171\n",
      "16                ([9, 70, 80, 60, 70, 3], 1e-05)       0.355511\n",
      "17                ([9, 70, 80, 60, 70, 3], 0.001)       0.350245\n",
      "18          ([9, 120, 100, 80, 60, 40, 3], 1e-06)       0.347916\n",
      "19          ([9, 120, 100, 80, 60, 40, 3], 1e-05)       0.364746\n",
      "20          ([9, 120, 100, 80, 60, 40, 3], 0.001)       0.389733\n",
      "21  ([9, 150, 120, 100, 110, 130, 140, 3], 1e-06)       0.350985\n",
      "22  ([9, 150, 120, 100, 110, 130, 140, 3], 1e-05)       0.419541\n",
      "23  ([9, 150, 120, 100, 110, 130, 140, 3], 0.001)       0.446075\n",
      "\n",
      "Mean J cost Results:\n",
      "                             Architecture, Lambda  Mean J Cost\n",
      "0                         ([9, 30, 25, 3], 1e-06)     0.182421\n",
      "1                         ([9, 30, 25, 3], 1e-05)     0.185581\n",
      "2                         ([9, 30, 25, 3], 0.001)     0.182828\n",
      "3                  ([9, 20, 15, 10, 5, 3], 1e-06)     0.205909\n",
      "4                  ([9, 20, 15, 10, 5, 3], 1e-05)     0.204139\n",
      "5                  ([9, 20, 15, 10, 5, 3], 0.001)     0.202434\n",
      "6                 ([9, 25, 20, 15, 10, 3], 1e-06)     0.197234\n",
      "7                 ([9, 25, 20, 15, 10, 3], 1e-05)     0.194430\n",
      "8                 ([9, 25, 20, 15, 10, 3], 0.001)     0.194773\n",
      "9                     ([9, 60, 80, 70, 3], 1e-06)     0.178379\n",
      "10                    ([9, 60, 80, 70, 3], 1e-05)     0.179853\n",
      "11                    ([9, 60, 80, 70, 3], 0.001)     0.166512\n",
      "12                ([9, 80, 60, 40, 30, 3], 1e-06)     0.183380\n",
      "13                ([9, 80, 60, 40, 30, 3], 1e-05)     0.170933\n",
      "14                ([9, 80, 60, 40, 30, 3], 0.001)     0.173448\n",
      "15                ([9, 70, 80, 60, 70, 3], 1e-06)     0.202536\n",
      "16                ([9, 70, 80, 60, 70, 3], 1e-05)     0.161716\n",
      "17                ([9, 70, 80, 60, 70, 3], 0.001)     0.161314\n",
      "18          ([9, 120, 100, 80, 60, 40, 3], 1e-06)     0.155775\n",
      "19          ([9, 120, 100, 80, 60, 40, 3], 1e-05)     0.152833\n",
      "20          ([9, 120, 100, 80, 60, 40, 3], 0.001)     0.159656\n",
      "21  ([9, 150, 120, 100, 110, 130, 140, 3], 1e-06)     0.164171\n",
      "22  ([9, 150, 120, 100, 110, 130, 140, 3], 1e-05)     0.143747\n",
      "23  ([9, 150, 120, 100, 110, 130, 140, 3], 0.001)     0.151014\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        self.weights = [np.random.randn(layers[i], layers[i+1]) for i in range(len(layers)-1)]\n",
    "        self.biases = [np.zeros((1, layers[i+1])) for i in range(len(layers)-1)]\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def forward_pass(self, X):\n",
    "        activations = [X]\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            z = np.dot(activations[-1], w) + b\n",
    "            activations.append(self.sigmoid(z))\n",
    "        return activations\n",
    "    \n",
    "    def backward_pass(self, X, Y, activations):\n",
    "        deltas = [(activations[-1] - Y) * self.sigmoid_derivative(activations[-1])]\n",
    "        for i in range(len(self.layers) - 2, 0, -1):\n",
    "            delta = np.dot(deltas[0], self.weights[i].T) * self.sigmoid_derivative(activations[i])\n",
    "            deltas.insert(0, delta)\n",
    "        return deltas\n",
    "    \n",
    "    \n",
    "    def compute_gradients(self, activations, deltas):\n",
    "        gradients_weights = [np.dot(activations[i].T, deltas[i]) for i in range(len(self.layers) - 1)]\n",
    "        gradients_biases = [np.sum(deltas[i], axis=0) for i in range(len(self.layers) - 1)]\n",
    "        return gradients_weights, gradients_biases\n",
    "    \n",
    "    def update_weights(self, gradients_weights, gradients_biases, learning_rate):\n",
    "        self.weights = [w - learning_rate * gw for w, gw in zip(self.weights, gradients_weights)]\n",
    "        self.biases = [b - learning_rate * gb for b, gb in zip(self.biases, gradients_biases)]\n",
    "    \n",
    "    def train(self, X, Y, learning_rate, lam, max_iterations, epsilon):\n",
    "        for iteration in range(max_iterations):\n",
    "            activations = self.forward_pass(X)\n",
    "            deltas = self.backward_pass(X, Y, activations)\n",
    "            gradients_weights, gradients_biases = self.compute_gradients(activations, deltas)\n",
    "            self.update_weights(gradients_weights, gradients_biases, learning_rate)\n",
    "            # Compute cost function\n",
    "            J = np.mean(np.square(activations[-1] - Y))\n",
    "            #print(f\"Iteration {iteration+1}, Cost: {J}\")\n",
    "            # Check for convergence\n",
    "            if J < epsilon:\n",
    "                #print(f\"Converged at cost :{J} while Epsilon:{epsilon} \")\n",
    "                return J\n",
    "        return J\n",
    "            \n",
    "\n",
    "    def accuracy(self, y_true, y_pred):\n",
    "        correct = np.sum(np.all(y_true == y_pred, axis=1))\n",
    "        return correct / len(y_true)\n",
    "\n",
    "\n",
    "    def f1_score(self, y_true, y_pred):\n",
    "        tp = np.sum(np.logical_and(y_true, y_pred))\n",
    "        fp = np.sum(np.logical_and(np.logical_not(y_true), y_pred))\n",
    "        fn = np.sum(np.logical_and(y_true, np.logical_not(y_pred)))\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        return f1\n",
    "\n",
    "\n",
    "    def evaluate(self, X_test, y_test, J):\n",
    "        activations = self.forward_pass(X_test)[-1]\n",
    "        y_pred = (activations > 0.5).astype(int)\n",
    "        acc = self.accuracy(y_test, y_pred)\n",
    "        f1 = self.f1_score(y_test, y_pred)\n",
    "        return J, acc, f1\n",
    "    \n",
    "    def k_fold_cross_validation(X, y, architectures, regularization_params, learning_rate, max_iterations, epsilon):\n",
    "        results_accuracy = {}\n",
    "        results_f1_score = {}\n",
    "        results_J_cost = {}\n",
    "        \n",
    "        num_splits = 10\n",
    "        fold_size = len(X) // num_splits\n",
    "\n",
    "        for arch in architectures:\n",
    "            for lam in regularization_params:\n",
    "                accuracy_list = []\n",
    "                f1_score_list = []\n",
    "                J_list = []\n",
    "                \n",
    "                for i in range(num_splits):\n",
    "                    start = i * fold_size\n",
    "                    end = (i + 1) * fold_size\n",
    "                    \n",
    "                    X_train = pd.concat([X[:start], X[end:]])\n",
    "                    y_train = np.concatenate([y[:start], y[end:]])\n",
    "                    X_test = X[start:end]\n",
    "                    y_test = y[start:end]\n",
    "\n",
    "                    mean = np.mean(X_train, axis=0)\n",
    "                    std = np.std(X_train, axis=0)\n",
    "                    X_train_normalized = (X_train - mean) / std\n",
    "                    X_test_normalized = (X_test - mean) / std\n",
    "\n",
    "                    model = NeuralNetwork(arch)\n",
    "                    J = model.train(X_train_normalized, y_train, learning_rate=learning_rate, lam=lam, max_iterations=max_iterations, epsilon=epsilon)\n",
    "                    J, accuracy, f1_score = model.evaluate(X_test_normalized, y_test, J)\n",
    "                    accuracy_list.append(accuracy)\n",
    "                    f1_score_list.append(f1_score)\n",
    "                    J_list.append(J)\n",
    "\n",
    "                mean_accuracy = np.mean(accuracy_list)\n",
    "                mean_f1_score = np.mean(f1_score_list)\n",
    "                mean_J_cost   = np.mean(J_list)\n",
    "\n",
    "                results_accuracy[(str(arch), lam)] = mean_accuracy\n",
    "                results_f1_score[(str(arch), lam)] = mean_f1_score\n",
    "                results_J_cost[(str(arch), lam)] = mean_J_cost\n",
    "\n",
    "        return results_accuracy, results_f1_score, results_J_cost\n",
    "\n",
    "#Load dataset\n",
    "data_file = \"/Users/noshitha/Downloads/contraceptive+method+choice/cmc.data\"\n",
    "column_names = [\n",
    "    \"Wife_age\", \"Wife_education\", \"Husband_education\", \"Number_of_children_ever_born\",\n",
    "    \"Wife_religion\", \"Wife_working\", \"Husband_occupation\", \"Standard-of-living_index\",\n",
    "    \"Media_exposure\", \"Contraceptive_method_used\"\n",
    "]\n",
    "cmc_df = pd.read_csv(data_file, names=column_names) \n",
    "\n",
    "# Extract features and target variable\n",
    "X_cmc = pd.get_dummies(cmc_df.drop(columns=['Contraceptive_method_used']))  # Features\n",
    "y_cmc = cmc_df['Contraceptive_method_used']  \n",
    "\n",
    "# Re-size data\n",
    "y_cmc_resized = y_cmc.values.reshape(-1, 1)\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the target variable\n",
    "y_encoded = encoder.fit_transform(y_cmc_resized)\n",
    "\n",
    "# Define model architectures and regularization parameters\n",
    "architectures = [\n",
    "    [X_cmc.shape[1], 30, 25, y_encoded.shape[1]], \n",
    "    [X_cmc.shape[1], 20, 15, 10, 5, y_encoded.shape[1]],\n",
    "    [X_cmc.shape[1], 25, 20, 15, 10, y_encoded.shape[1]],\n",
    "    [X_cmc.shape[1], 60, 80, 70, y_encoded.shape[1]],  \n",
    "    [X_cmc.shape[1], 80, 60, 40, 30, y_encoded.shape[1]],    \n",
    "    [X_cmc.shape[1], 70, 80, 60, 70, y_encoded.shape[1]], \n",
    "    [X_cmc.shape[1], 120, 100, 80, 60, 40, y_encoded.shape[1]],\n",
    "    [X_cmc.shape[1], 150, 120, 100, 110, 130, 140, y_encoded.shape[1]]\n",
    "]\n",
    "\n",
    "regularization_params = [0.000001, 0.00001, 0.001]\n",
    "\n",
    "# Initialize lists to store results\n",
    "results_accuracy = {}\n",
    "results_f1_score = {}\n",
    "results_J_cost = {}\n",
    "\n",
    "# Perform stratified k-fold cross-validation\n",
    "results_accuracy, results_f1_score, results_J_cost = NeuralNetwork.k_fold_cross_validation(X_cmc, y_encoded, architectures, regularization_params, learning_rate=0.0001, max_iterations=2500, epsilon=0.005)\n",
    "\n",
    "# Convert the results into a DataFrame for tabular representation\n",
    "accuracy_df = pd.DataFrame(list(results_accuracy.items()), columns=['Architecture, Lambda', 'Mean Accuracy'])\n",
    "f1_score_df = pd.DataFrame(list(results_f1_score.items()), columns=['Architecture, Lambda', 'Mean F1 Score'])\n",
    "J_cost_df = pd.DataFrame(list(results_J_cost.items()), columns=['Architecture, Lambda', 'Mean J Cost'])\n",
    "\n",
    "print(\"Mean Accuracy Results:\")\n",
    "print(accuracy_df)\n",
    "print(\"\\nMean F1 Score Results:\")\n",
    "print(f1_score_df)\n",
    "print(\"\\nMean J cost Results:\")\n",
    "print(J_cost_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4f71cdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Architecture, Lambda</th>\n",
       "      <th>Mean Accuracy</th>\n",
       "      <th>Mean F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([9, 30, 25, 3], 1e-06)</td>\n",
       "      <td>0.219048</td>\n",
       "      <td>0.289704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>([9, 30, 25, 3], 1e-05)</td>\n",
       "      <td>0.191837</td>\n",
       "      <td>0.256600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>([9, 30, 25, 3], 0.001)</td>\n",
       "      <td>0.217007</td>\n",
       "      <td>0.289096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>([9, 20, 15, 10, 5, 3], 1e-06)</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>0.010811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>([9, 20, 15, 10, 5, 3], 1e-05)</td>\n",
       "      <td>0.027891</td>\n",
       "      <td>0.041994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>([9, 20, 15, 10, 5, 3], 0.001)</td>\n",
       "      <td>0.025170</td>\n",
       "      <td>0.041075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>([9, 25, 20, 15, 10, 3], 1e-06)</td>\n",
       "      <td>0.114966</td>\n",
       "      <td>0.171289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>([9, 25, 20, 15, 10, 3], 1e-05)</td>\n",
       "      <td>0.155782</td>\n",
       "      <td>0.220542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>([9, 25, 20, 15, 10, 3], 0.001)</td>\n",
       "      <td>0.144218</td>\n",
       "      <td>0.208499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>([9, 60, 80, 70, 3], 1e-06)</td>\n",
       "      <td>0.240816</td>\n",
       "      <td>0.311444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>([9, 60, 80, 70, 3], 1e-05)</td>\n",
       "      <td>0.264626</td>\n",
       "      <td>0.340499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>([9, 60, 80, 70, 3], 0.001)</td>\n",
       "      <td>0.278912</td>\n",
       "      <td>0.353113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>([9, 80, 60, 40, 30, 3], 1e-06)</td>\n",
       "      <td>0.255102</td>\n",
       "      <td>0.330666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>([9, 80, 60, 40, 30, 3], 1e-05)</td>\n",
       "      <td>0.242177</td>\n",
       "      <td>0.304899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>([9, 80, 60, 40, 30, 3], 0.001)</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.324657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>([9, 70, 80, 60, 70, 3], 1e-06)</td>\n",
       "      <td>0.282993</td>\n",
       "      <td>0.388171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>([9, 70, 80, 60, 70, 3], 1e-05)</td>\n",
       "      <td>0.287755</td>\n",
       "      <td>0.355511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>([9, 70, 80, 60, 70, 3], 0.001)</td>\n",
       "      <td>0.284354</td>\n",
       "      <td>0.350245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>([9, 120, 100, 80, 60, 40, 3], 1e-06)</td>\n",
       "      <td>0.280952</td>\n",
       "      <td>0.347916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>([9, 120, 100, 80, 60, 40, 3], 1e-05)</td>\n",
       "      <td>0.305442</td>\n",
       "      <td>0.364746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>([9, 120, 100, 80, 60, 40, 3], 0.001)</td>\n",
       "      <td>0.317007</td>\n",
       "      <td>0.389733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>([9, 150, 120, 100, 110, 130, 140, 3], 1e-06)</td>\n",
       "      <td>0.218367</td>\n",
       "      <td>0.350985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>([9, 150, 120, 100, 110, 130, 140, 3], 1e-05)</td>\n",
       "      <td>0.334014</td>\n",
       "      <td>0.419541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>([9, 150, 120, 100, 110, 130, 140, 3], 0.001)</td>\n",
       "      <td>0.336735</td>\n",
       "      <td>0.446075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Architecture, Lambda  Mean Accuracy  \\\n",
       "0                         ([9, 30, 25, 3], 1e-06)       0.219048   \n",
       "1                         ([9, 30, 25, 3], 1e-05)       0.191837   \n",
       "2                         ([9, 30, 25, 3], 0.001)       0.217007   \n",
       "3                  ([9, 20, 15, 10, 5, 3], 1e-06)       0.006803   \n",
       "4                  ([9, 20, 15, 10, 5, 3], 1e-05)       0.027891   \n",
       "5                  ([9, 20, 15, 10, 5, 3], 0.001)       0.025170   \n",
       "6                 ([9, 25, 20, 15, 10, 3], 1e-06)       0.114966   \n",
       "7                 ([9, 25, 20, 15, 10, 3], 1e-05)       0.155782   \n",
       "8                 ([9, 25, 20, 15, 10, 3], 0.001)       0.144218   \n",
       "9                     ([9, 60, 80, 70, 3], 1e-06)       0.240816   \n",
       "10                    ([9, 60, 80, 70, 3], 1e-05)       0.264626   \n",
       "11                    ([9, 60, 80, 70, 3], 0.001)       0.278912   \n",
       "12                ([9, 80, 60, 40, 30, 3], 1e-06)       0.255102   \n",
       "13                ([9, 80, 60, 40, 30, 3], 1e-05)       0.242177   \n",
       "14                ([9, 80, 60, 40, 30, 3], 0.001)       0.257143   \n",
       "15                ([9, 70, 80, 60, 70, 3], 1e-06)       0.282993   \n",
       "16                ([9, 70, 80, 60, 70, 3], 1e-05)       0.287755   \n",
       "17                ([9, 70, 80, 60, 70, 3], 0.001)       0.284354   \n",
       "18          ([9, 120, 100, 80, 60, 40, 3], 1e-06)       0.280952   \n",
       "19          ([9, 120, 100, 80, 60, 40, 3], 1e-05)       0.305442   \n",
       "20          ([9, 120, 100, 80, 60, 40, 3], 0.001)       0.317007   \n",
       "21  ([9, 150, 120, 100, 110, 130, 140, 3], 1e-06)       0.218367   \n",
       "22  ([9, 150, 120, 100, 110, 130, 140, 3], 1e-05)       0.334014   \n",
       "23  ([9, 150, 120, 100, 110, 130, 140, 3], 0.001)       0.336735   \n",
       "\n",
       "    Mean F1 Score  \n",
       "0        0.289704  \n",
       "1        0.256600  \n",
       "2        0.289096  \n",
       "3        0.010811  \n",
       "4        0.041994  \n",
       "5        0.041075  \n",
       "6        0.171289  \n",
       "7        0.220542  \n",
       "8        0.208499  \n",
       "9        0.311444  \n",
       "10       0.340499  \n",
       "11       0.353113  \n",
       "12       0.330666  \n",
       "13       0.304899  \n",
       "14       0.324657  \n",
       "15       0.388171  \n",
       "16       0.355511  \n",
       "17       0.350245  \n",
       "18       0.347916  \n",
       "19       0.364746  \n",
       "20       0.389733  \n",
       "21       0.350985  \n",
       "22       0.419541  \n",
       "23       0.446075  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge accuracy and f1_score DataFrames on 'Architecture, Lambda'\n",
    "merged_df = pd.merge(accuracy_df, f1_score_df, on='Architecture, Lambda')\n",
    "\n",
    "# Merge the merged DataFrame with J_cost_df on 'Architecture, Lambda'\n",
    "final_df = pd.merge(merged_df, J_cost_df, on='Architecture, Lambda')\n",
    "\n",
    "# Rename columns for clarity\n",
    "merged_df.columns = ['Architecture, Lambda', 'Mean Accuracy', 'Mean F1 Score']\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08576023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Function to generate mini-batches\n",
    "def generate_mini_batches(X, y, batch_size):\n",
    "    num_samples = X.shape[0]\n",
    "    num_batches = num_samples // batch_size\n",
    "    mini_batches = []\n",
    "    shuffled_indices = np.random.permutation(num_samples)\n",
    "    X_shuffled = X[shuffled_indices]\n",
    "    y_shuffled = y[shuffled_indices]\n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        mini_batches.append((X_shuffled[start_idx:end_idx], y_shuffled[start_idx:end_idx]))\n",
    "    if num_samples % batch_size != 0:\n",
    "        mini_batches.append((X_shuffled[num_batches*batch_size:], y_shuffled[num_batches*batch_size:]))\n",
    "    return mini_batches\n",
    "\n",
    "\n",
    "def train_mini_batch(X_train, y_train, X_test, y_test, model, learning_rate,lam, batch_size, max_iterations, epsilon):\n",
    "    training_errors = []\n",
    "    testing_errors = []\n",
    "    for iteration in range(max_iterations):\n",
    "        mini_batches = generate_mini_batches(X_train, y_train, batch_size)\n",
    "        for mini_batch in mini_batches:\n",
    "            X_mini_batch, y_mini_batch = mini_batch\n",
    "            J = model.train(X_mini_batch, y_mini_batch, learning_rate=learning_rate, lam=lam, max_iterations=1, epsilon=epsilon)\n",
    "        training_cost = np.mean(np.square(model.forward_pass(X_train)[-1] - y_train))  # Compute training cost\n",
    "        testing_cost = np.mean(np.square(model.forward_pass(X_test)[-1] - y_test))  # Compute testing cost\n",
    "        training_errors.append(training_cost)\n",
    "        testing_errors.append(testing_cost)\n",
    "        #print(f\"Iteration {iteration+1}, Training Cost: {training_cost}, Testing Cost: {testing_cost}\")\n",
    "        # Check for convergence\n",
    "        if training_cost < epsilon:\n",
    "            #print(f\"Converged at training cost :{training_cost} while Epsilon:{epsilon} \")\n",
    "            break\n",
    "    return training_errors, testing_errors\n",
    "\n",
    "# Plot learning curve\n",
    "def plot_learning_curve(training_errors, testing_errors, step_size):\n",
    "    iterations = range(1, len(training_errors) + 1)\n",
    "    plt.plot(iterations, training_errors, label='Training Error')\n",
    "    plt.plot(iterations, testing_errors, label='Testing Error')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.xlabel('Number of Training Samples')\n",
    "    plt.ylabel('J values ')\n",
    "    plt.xticks(np.arange(1, len(training_errors) + 1, step=step_size))\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bddf927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define your neural network model and parameters\n",
    "model = NeuralNetwork([X_cmc.shape[1], 70, 80, 60, 70, y_encoded.shape[1]])  \n",
    "learning_rate = 0.0001\n",
    "batch_size = 32\n",
    "max_iterations = 2500\n",
    "epsilon = 0.005\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cmc, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "X_train_normalized = (X_train - mean) / std\n",
    "X_test_normalized = (X_test - mean) / std\n",
    "\n",
    "# Train the model using mini-batch gradient descent\n",
    "training_errors, testing_errors = train_mini_batch(X_train_normalized.to_numpy(), y_train, X_test_normalized.to_numpy(), y_test, model, learning_rate,1e-05, batch_size, max_iterations, epsilon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0025b465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the learning curve\n",
    "step_size = 50  # Adjust as needed\n",
    "plot_learning_curve(training_errors, testing_errors, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4cc6e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
